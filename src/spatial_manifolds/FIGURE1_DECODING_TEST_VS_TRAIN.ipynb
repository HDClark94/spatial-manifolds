{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a830750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pynapple as nap\n",
    "from spatial_manifolds.toroidal import *\n",
    "from spatial_manifolds.behaviour_plots import *\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from scipy.spatial import distance\n",
    "from spatial_manifolds.circular_decoder import circular_decoder, cross_validate_decoder, cross_validate_decoder_time, circular_nanmean\n",
    "\n",
    "from spatial_manifolds.data.curation import curate_clusters\n",
    "from scipy.stats import zscore\n",
    "from spatial_manifolds.util import gaussian_filter_nan\n",
    "from spatial_manifolds.predictive_grid import compute_travel_projected, wrap_list\n",
    "from spatial_manifolds.behaviour_plots import *\n",
    "from spatial_manifolds.behaviour_plots import trial_cat_priority\n",
    "from spatial_manifolds.detect_grids import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fig_path = '/Users/harryclark/Documents/figs/FIGURE1/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46052204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'M29D22' throws errors I think because it has too few disengaged trials\n",
    "# 'M26D14' throws an error, doesn't have field spacing column for the cell classification in of1\n",
    "# 'M22D35' throws an error, doesn't have field spacing column for the cell classification in of1\n",
    "\n",
    "sessions_to_use = ['M27D16', 'M29D22', \n",
    "                   'M21D18', 'M21D23', 'M21D24', 'M21D25', 'M21D26',\n",
    "                   'M22D34', 'M22D36', 'M25D22', 'M25D23',\n",
    "                   'M25D24', 'M25D25', 'M28D16', 'M28D17', 'M28D18',\n",
    "                   'M28D20', 'M28D23', 'M28D25', 'M29D16',\n",
    "                   'M29D17', 'M29D18', 'M29D19', 'M29D20', 'M29D21', \n",
    "                   'M29D23', 'M29D25', 'M20D14', 'M20D22', 'M29D22'\n",
    "                   'M20D23', 'M20D25', 'M20D26', 'M21D17', 'M21D21',\n",
    "                   'M21D22', 'M22D33', 'M22D37', 'M22D38', 'M22D39',\n",
    "                   'M22D40', 'M22D41', 'M25D17', 'M25D19', 'M25D20',\n",
    "                   'M26D11', 'M26D12', 'M26D13', 'M26D15',\n",
    "                   'M26D16', 'M26D17', 'M26D19', 'M27D17',\n",
    "                   'M27D18', 'M27D19', 'M27D20', 'M27D21', 'M27D24',\n",
    "                   'M27D26', 'M28D19', 'M28D21', 'M20D15', 'M20D16',\n",
    "                   'M20D17', 'M20D18', 'M20D19', 'M20D20', 'M20D21', \n",
    "                   'M20D24', 'M20D27', 'M20D28', 'M21D15', 'M21D16', \n",
    "                   'M21D19', 'M21D20', 'M21D27', 'M21D28', 'M25D16',\n",
    "                   'M26D18', 'M27D23']\n",
    "\n",
    "#sessions_to_use = ['M21D18', 'M21D23', 'M21D24', 'M21D25', 'M21D26',\n",
    "#                   'M22D34', 'M22D35', 'M22D36', 'M25D22', 'M25D23',\n",
    "#                   'M25D24', 'M25D25', 'M28D16', 'M28D17', 'M28D18']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for session in sessions_to_use:\n",
    "    mouse = session.split('M')[-1].split('D')[0]\n",
    "    day = session.split('M')[-1].split('D')[-1]\n",
    "\n",
    "    # collect cell classifications\n",
    "    gcs, ngs, ns, sc, ngs_ns, all = cell_classification_of1(mouse, day, percentile_threshold=99) # subset\n",
    "    rc, rsc, vr_ns = cell_classification_vr(mouse, day)\n",
    "    tcs, tcs_time, autocorrs, last_ephys_bin, beh, clusters = compute_vr_tcs(mouse, day)\n",
    "    \n",
    "    # get session info\n",
    "    trial_groups, trial_colors = get_trial_groups_and_colors(beh, last_ephys_bin, tl, bs)\n",
    "    sorted_trial_indices, sorted_trial_colors = get_sorted_trials_and_colors(beh, last_ephys_bin, tl, bs)\n",
    "    tns = beh['trial_number']\n",
    "    dt = beh['travel']-((tns[0]-1)*tl)\n",
    "    n_bins = int(int(((np.ceil(np.nanmax(dt))//tl)+1)*tl)/bs)\n",
    "    max_bound = int(((np.ceil(np.nanmax(dt))//tl)+1)*tl)\n",
    "    min_bound = 0\n",
    "    dt_bins = np.arange(0,max_bound,bs)\n",
    "    x_true_dt = dt_bins[:last_ephys_bin]\n",
    "    true_position = x_true_dt%tl\n",
    "    trial_numbers = (x_true_dt//tl)+beh['trials']['number'][0]\n",
    "\n",
    "    # loop over combinations\n",
    "    for train_set, train_set_label in zip([np.array(['hit']), np.array(['try', 'run'])], ['eng', 'diseng']):\n",
    "        for test_set, test_set_label in zip([np.array(['hit']), np.array(['try', 'run'])], ['eng', 'diseng']):\n",
    "            for trial_type_set, trial_type_set_label in zip([np.array(['b','nb']), np.array(['b']), np.array(['nb'])], ['b_nb', 'b', 'nb']):\n",
    "                for cluster_ids, cell_type_label in zip([gcs.cluster_id.values, ngs.cluster_id.values, vr_ns.cluster_id.values], ['GC', 'NGS', 'NS']):\n",
    "\n",
    "                    tns_to_decode = np.array(beh['trials']['number'][(np.isin(beh['trials']['type'], trial_type_set)) &\n",
    "                                                                    (np.isin(beh['trials']['performance'], test_set))])\n",
    "                    tns_to_train = np.array(beh['trials']['number'][(np.isin(beh['trials']['type'], trial_type_set)) &\n",
    "                                                                    (np.isin(beh['trials']['performance'], train_set))]) \n",
    "                    \n",
    "                    tns_to_decode = tns_to_decode[tns_to_decode<=np.nanmax(trial_numbers)] # handles last ephys trials\n",
    "                    tns_to_train = tns_to_train[tns_to_train<=np.nanmax(trial_numbers)] # handles last ephys trials\n",
    "                    \n",
    "                    print(f'n clusters: {len(cluster_ids)}')\n",
    "                    print(f'n trials to decode: {len(tns_to_decode)}')\n",
    "                    print(f'n trials to train {len(tns_to_train)}')\n",
    "\n",
    "                    if len(cluster_ids)>10 and len(tns_to_decode) > 5 and len(tns_to_train) > 5:\n",
    "                        tcs_ = {cluster_id: tcs[cluster_id] for cluster_id in cluster_ids if cluster_id in tcs}\n",
    "\n",
    "                        predictions, errors = cross_validate_decoder(tcs_, true_position, trial_numbers, tns_to_decode, \n",
    "                                                                    tns_to_train, tl, bs, train=0.9, n=10, verbose=False)\n",
    "                        \n",
    "                        avg_predictions = circular_nanmean(predictions, tl, axis=2)\n",
    "                        avg_errors = np.nanmean(errors, axis=2)\n",
    "                        \n",
    "                        tmp = pd.DataFrame()\n",
    "                        tmp['train_set'] = [train_set_label]\n",
    "                        tmp['test_set'] = [test_set_label]\n",
    "                        tmp['cell_type'] = [cell_type_label]\n",
    "                        tmp['trial_type'] = [trial_type_set_label]\n",
    "                        tmp['error'] = [np.nanmean(avg_errors)]\n",
    "                        tmp['error_over_location'] = [avg_errors.mean(axis=0)]\n",
    "                        tmp['mouse'] = [mouse]\n",
    "                        tmp['day'] = [day]\n",
    "                        tmp['mouse_day'] = [session]\n",
    "                        \n",
    "                        df = pd.concat([df, tmp], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6368d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('/Users/harryclark/Downloads/test_train_linear_decoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c5d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/Users/harryclark/Downloads/test_train_linear_decoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type_label in ['GC', 'NGS', 'NS']:\n",
    "    for trial_type_set_label in ['b', 'nb']:\n",
    "        ct_df = df[df['cell_type'] == cell_type_label]\n",
    "        ct_df = ct_df[ct_df['trial_type'] == trial_type_set_label]\n",
    "\n",
    "        # Calculate average error for each train_set and test_set combination\n",
    "        avg_error = ct_df.groupby(['train_set', 'test_set'])['error'].mean().reset_index()\n",
    "        eng_eng_error = avg_error[(avg_error['train_set'] == 'eng') & (avg_error['test_set'] == 'eng')].error.iloc[0]\n",
    "        eng_diseng_error = avg_error[(avg_error['train_set'] == 'eng') & (avg_error['test_set'] == 'diseng')].error.iloc[0]\n",
    "        diseng_eng_error = avg_error[(avg_error['train_set'] == 'diseng') & (avg_error['test_set'] == 'eng')].error.iloc[0]\n",
    "        diseng_diseng_error = avg_error[(avg_error['train_set'] == 'diseng') & (avg_error['test_set'] == 'diseng')].error.iloc[0]\n",
    "\n",
    "        # Create bar plot\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(2, 2))\n",
    "        ax.bar(x=[1,2,4,5], height=[eng_eng_error, \n",
    "                                    eng_diseng_error, \n",
    "                                    diseng_eng_error, \n",
    "                                    diseng_diseng_error], \n",
    "                                    color=[get_color_for_group(('rz1',trial_type_set_label,'hit')),\n",
    "                                           get_color_for_group(('rz1',trial_type_set_label,'run')),\n",
    "                                           get_color_for_group(('rz1',trial_type_set_label,'hit')),\n",
    "                                           get_color_for_group(('rz1',trial_type_set_label,'run'))],\n",
    "                                    edgecolor=[get_color_for_group(('rz1',trial_type_set_label,'hit')),\n",
    "                                               get_color_for_group(('rz1',trial_type_set_label,'hit')),\n",
    "                                               get_color_for_group(('rz1',trial_type_set_label,'run')),\n",
    "                                               get_color_for_group(('rz1',trial_type_set_label,'run'))])\n",
    "\n",
    "        # Overlay line plot for individual trajectories\n",
    "        for mouse_day in ct_df['mouse_day'].unique():\n",
    "            subset = ct_df[ct_df['mouse_day'] == mouse_day]\n",
    "\n",
    "            eng_eng_error = subset[(subset['train_set'] == 'eng') & (subset['test_set'] == 'eng')].error\n",
    "            eng_diseng_error = subset[(subset['train_set'] == 'eng') & (subset['test_set'] == 'diseng')].error\n",
    "            diseng_eng_error = subset[(subset['train_set'] == 'diseng') & (subset['test_set'] == 'eng')].error\n",
    "            diseng_diseng_error = subset[(subset['train_set'] == 'diseng') & (subset['test_set'] == 'diseng')].error\n",
    "\n",
    "            if len(eng_eng_error)>0 and len(eng_diseng_error)>0 and len(diseng_eng_error)>0 and len(diseng_diseng_error)>0:\n",
    "                ax.plot([1,2], [eng_eng_error.iloc[0], eng_diseng_error.iloc[0]], linestyle='-', color='grey', alpha=0.5)\n",
    "                ax.plot([4,5], [diseng_eng_error.iloc[0], diseng_diseng_error.iloc[0]], linestyle='-', color='grey', alpha=0.5)\n",
    "\n",
    "        ax.set_xticks([1,2,4,5])\n",
    "        ax.set_xticklabels(['Eng', 'Dis', 'Eng', 'Dis'])\n",
    "        ax.set_title(f'{cell_type_label}:{trial_type_set_label}')\n",
    "        ax.set_ylim(0,60)\n",
    "        ax.set_ylabel('Decoding error (cm)')\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'{fig_path}/Decoding_vs_test_train_sets_{cell_type_label}_tt_{trial_type_set_label}.pdf', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac5ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdt2dna(pandas_series):\n",
    "    new_array = []\n",
    "    for i in range(len(pandas_series)):\n",
    "        element = pandas_series.iloc[i]\n",
    "\n",
    "        if len(np.shape(element)) == 0:\n",
    "            new_array.append([element])\n",
    "        else:\n",
    "            new_array.append(element)\n",
    "\n",
    "    return np.array(new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d85d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for cell_type_label in ['GC', 'NGS', 'NS']:\n",
    "    for trial_type_set_label in ['b', 'nb']:\n",
    "        ct_df = df[df['cell_type'] == cell_type_label]\n",
    "        ct_df = ct_df[ct_df['trial_type'] == trial_type_set_label]\n",
    "            \n",
    "        # Calculate average error for each train_set and test_set combination\n",
    "        eng_eng = ct_df[(ct_df['train_set'] == 'eng') & (ct_df['test_set'] == 'eng')]\n",
    "        eng_diseng = ct_df[(ct_df['train_set'] == 'eng') & (ct_df['test_set'] == 'diseng')]\n",
    "        \n",
    "\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(2, 2))\n",
    "        ax.axvspan(\n",
    "            90,110,\n",
    "            alpha=0.2,\n",
    "            zorder=-10,\n",
    "            edgecolor='none',\n",
    "            facecolor='grey',\n",
    "        )\n",
    "        ax.plot(np.arange(bs/2, (tl+bs/2), bs), np.nanmean(cdt2dna(eng_eng['error_over_location']), axis=0), color= get_color_for_group(('rz1',trial_type_set_label,'hit')))\n",
    "        ax.plot(np.arange(bs/2, (tl+bs/2), bs), np.nanmean(cdt2dna(eng_diseng['error_over_location']), axis=0), color= get_color_for_group(('rz1',trial_type_set_label,'run')))\n",
    "        ax.fill_between(np.arange(bs/2, (tl+bs/2), bs), \n",
    "                        np.nanmean(cdt2dna(eng_eng['error_over_location']), axis=0) + stats.sem(cdt2dna(eng_eng['error_over_location']), nan_policy='omit'),\n",
    "                        np.nanmean(cdt2dna(eng_eng['error_over_location']), axis=0) - stats.sem(cdt2dna(eng_eng['error_over_location']), nan_policy='omit'),\n",
    "                        color= get_color_for_group(('rz1',trial_type_set_label,'hit')), alpha=0.3)\n",
    "        ax.fill_between(np.arange(bs/2, (tl+bs/2), bs), \n",
    "                        np.nanmean(cdt2dna(eng_diseng['error_over_location']), axis=0) + stats.sem(cdt2dna(eng_diseng['error_over_location']), nan_policy='omit'),\n",
    "                        np.nanmean(cdt2dna(eng_diseng['error_over_location']), axis=0) - stats.sem(cdt2dna(eng_diseng['error_over_location']), nan_policy='omit'),\n",
    "                        color= get_color_for_group(('rz1',trial_type_set_label,'run')), alpha=0.3)\n",
    "\n",
    "        ax.set_title(f'{cell_type_label}:{trial_type_set_label}')\n",
    "        ax.set_xlim(0,tl)    \n",
    "        ax.set_ylim(0,60)\n",
    "        ax.set_xlabel('Position (cm)')\n",
    "        ax.set_ylabel('Decoding error (cm)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        fig.savefig(f'{fig_path}/Decoding_vs_location_test_train_sets_{cell_type_label}_tt_{trial_type_set_label}.pdf', dpi=300, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc2902",
   "metadata": {},
   "source": [
    "do some stats using mixed linear models to determine the significance of decoder performances in different cell populations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "'''\n",
    "Model Construction Notes:\n",
    "1. Fixed effects: age, sex, reward order, task struct (0 = block, 1 = alt), context ID (all categorical), session (continuous). \n",
    "2. Added context & taststruct to agegroup interaction terms.\n",
    "3. Random effect is animal ID in that sessions are grouped by belonging to the same animal.\n",
    "4. Modeling random intercepts & slopes captures learning rate differences that I'm hoping to model.\n",
    "\n",
    "'''\n",
    "\n",
    "# Get LMM & Print Results\n",
    "mtask = smf.mixedlm('ReqRate ~ 1 + Session + Session:C(AgeGroup) + C(AgeGroup) + Satiety + C(Sex):C(AgeGroup) + C(Sex) + C(RewardOrder) + C(ContextID) + C(ContextID):C(AgeGroup) + C(TaskStruct) + C(TaskStruct):C(AgeGroup)', groups = 'AnimalID', re_formula = '~1 + Session', data = df).fit(reml= True)\n",
    "print(mtask.summary())\n",
    "print(mtask.wald_test_terms(scalar = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548527b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
