{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pynapple as nap\n",
    "from spatial_manifolds.toroidal import *\n",
    "from spatial_manifolds.behaviour_plots import *\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "from cebra import CEBRA\n",
    "import cebra.integrations.plotly\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "\n",
    "from spatial_manifolds.circular_decoder import circular_decoder, cross_validate_decoder, cross_validate_decoder_time, circular_nanmean\n",
    "from spatial_manifolds.data.curation import curate_clusters\n",
    "from scipy.stats import zscore\n",
    "from spatial_manifolds.util import gaussian_filter_nan\n",
    "from spatial_manifolds.predictive_grid import compute_travel_projected, wrap_list\n",
    "from spatial_manifolds.behaviour_plots import *\n",
    "from spatial_manifolds.behaviour_plots import trial_cat_priority\n",
    "from spatial_manifolds.detect_grids import *\n",
    "from spatial_manifolds.brainrender_helper import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hdbscan\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from IPython.display import HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = '/Users/harryclark/Documents/figs/FIGURE1/'\n",
    "mouse = 29\n",
    "day = 23\n",
    "\n",
    "# good examples include \n",
    "#mice = [25, 25, 26, 27, 29, 28]\n",
    "#days = [25, 24, 18, 26, 23, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs, ngs, ns, sc, ngs_ns, all = cell_classification_of1(mouse, day, percentile_threshold=99) # subset\n",
    "rc, rsc, vr_ns = cell_classification_vr(mouse, day)\n",
    "\n",
    "g_m_ids, g_m_cluster_ids = HDBSCAN_grid_modules(gcs, all, mouse, day, min_cluster_size=3, cluster_selection_epsilon=3, \n",
    "                                                figpath=fig_path, curate_with_vr=True, curate_with_brain_region=True) # create grid modules using HDBSCAN    \n",
    "\n",
    "plot_grid_modules_rate_maps(gcs, g_m_ids, g_m_cluster_ids, mouse, day, figpath=fig_path)\n",
    "\n",
    "# we now have cluster ids classified into modules, non grid spatial cells and non spatial cells \n",
    "# as defined by activity in the open field\n",
    "g_m_cluster_ids = sorted(g_m_cluster_ids, key=len, reverse=True) \n",
    "cluster_ids_by_group = []\n",
    "cluster_ids_by_group.extend(g_m_cluster_ids) # grid cells by module [0,1,2...]\n",
    "cluster_ids_by_group.append(ngs.cluster_id.values.tolist()) # non grid spatial [-4]\n",
    "cluster_ids_by_group.append(ns.cluster_id.values.tolist()) # non spatial cells [-3]\n",
    "cluster_ids_by_group.append(gcs.cluster_id.values.tolist()) # all grid cells [-2]\n",
    "cluster_ids_by_group.append(sc.cluster_id.values.tolist()) # speed cells [-1]\n",
    "\n",
    "for m, cluster_ids in enumerate(cluster_ids_by_group):\n",
    "    plot_vr_rate_maps(mouse, day, cluster_ids, label=f'{m}', figpath=fig_path)\n",
    "\n",
    "#plot_vr_rate_maps(mouse, day, rc.cluster_id.values, label=f'ramp_cells', figpath=fig_path)\n",
    "#plot_vr_rate_maps(mouse, day, rsc.cluster_id.values, label=f'speed_ramp_cells', figpath=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stops_mouse_day(mouse, day, figpath=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_outbound_homebound_similarity(mouse, day, cluster_id_groups=[cluster_ids_by_group[-2], \n",
    "                                                                      cluster_ids_by_group[-4], \n",
    "                                                                      vr_ns.cluster_id.values],\n",
    "                                                                      cluster_id_labels=['GC', 'NGS', 'NS'],\n",
    "                                                                      figpath=''):\n",
    "    tcs, tcs_time, autocorrs, last_ephys_bin, beh, clusters = compute_vr_tcs(mouse, day, apply_zscore=False)           \n",
    "    trial_groups, trial_colors = get_trial_groups_and_colors(beh, last_ephys_bin, tl, bs)\n",
    "    sorted_trial_indices, sorted_trial_colors = get_sorted_trials_and_colors(beh, last_ephys_bin, tl, bs)\n",
    "   \n",
    "    fig, ax = plt.subplots(1,1, figsize=(2.3,2.3))\n",
    "    colors = ['black', '#707B8F', '#A7A388']\n",
    "    for i, (cluster_ids, label) in enumerate(zip(cluster_id_groups, cluster_id_labels)):\n",
    "        outbound_similarities = []\n",
    "        homebounds_similarities = []\n",
    "        for id in cluster_ids:\n",
    "            tc = tcs[id]\n",
    "            tc = gaussian_filter(np.nan_to_num(tc).astype(np.float64), sigma=2.5)\n",
    "            tc = tc[:last_ephys_bin] # only want bins with ephys data in it\n",
    "            tc = zscore(tc)\n",
    "\n",
    "            x, b_y = get_avg_profile(tc, bs, tl, mask=trial_groups==('rz1bhit'))\n",
    "            x, nb_y = get_avg_profile(tc, bs, tl, mask=trial_groups==('rz1nbhit'))\n",
    "\n",
    "            ob =  stats.pearsonr(b_y[:int(0.5*tl/bs)], nb_y[:int(0.5*tl/bs)])[0]\n",
    "            hb = stats.pearsonr(b_y[int(0.5*tl/bs):], nb_y[int(0.5*tl/bs):])[0]\n",
    "\n",
    "            outbound_similarities.append(ob)\n",
    "            homebounds_similarities.append(hb)\n",
    "        ax.scatter(outbound_similarities, homebounds_similarities, color=colors[i], label=label, alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel('Outbound similarity')\n",
    "    ax.set_ylabel('Homebound similarity')\n",
    "    ax.plot(np.arange(-1,1,0.1), np.arange(-1,1,0.1), linestyle='dashed', color='black')\n",
    "    ax.set_ylim(-1,1)\n",
    "    ax.set_xlim(-1,1)\n",
    "    ax.set_xticks([-1, 0, 1])\n",
    "    ax.set_yticks([-1, 0, 1])\n",
    "\n",
    "\n",
    "    fig.legend()\n",
    "    fig.savefig(f'{figpath}/M{mouse}D{day}_similarity_outbound_homebound.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_outbound_homebound_similarity(mouse, day, cluster_id_groups=[cluster_ids_by_group[-2], \n",
    "                                                                  cluster_ids_by_group[-4], \n",
    "                                                                  vr_ns.cluster_id.values],\n",
    "                                                                  cluster_id_labels=['GC', 'NGS', 'NS'],\n",
    "                                                                  figpath=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "from cebra import CEBRA\n",
    "import cebra.integrations.plotly\n",
    "from spatial_manifolds.cebra_helper import encode_1d_to_2d, plot_embeddings\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "cluster_id_groups=[cluster_ids_by_group[-2], cluster_ids_by_group[-4], vr_ns.cluster_id.values]\n",
    "cluster_id_labels=['GC', 'NGS', 'NS']\n",
    "\n",
    "tcs, tcs_time, autocorrs, last_ephys_bin, beh, clusters = compute_vr_tcs(mouse, day, apply_zscore=False)           \n",
    "trial_groups, trial_colors = get_trial_groups_and_colors(beh, last_ephys_bin, tl, bs)\n",
    "sorted_trial_indices, sorted_trial_colors = get_sorted_trials_and_colors(beh, last_ephys_bin, tl, bs)\n",
    "last_ephys_time_bin = clusters[clusters.index[0]].count(bin_size=time_bs, time_units = 'ms').index[-1]\n",
    "ep = nap.IntervalSet(start=0, end=last_ephys_time_bin, time_units = 's')\n",
    "speed_in_time = beh['S'].bin_average(bin_size=time_bs, time_units = 'ms', ep=ep)\n",
    "dt_in_time = beh['travel'].bin_average(bin_size=time_bs, time_units = 'ms', ep=ep)-((beh['trial_number'][0]-1)*tl)\n",
    "pos_in_time = dt_in_time%tl\n",
    "time_in_time = np.arange(((time_bs/1000)/2), len(pos_in_time)*(time_bs/1000)+((time_bs/1000)/2), time_bs/1000)\n",
    "trial_number_in_time = (dt_in_time//tl)+beh['trial_number'][0]\n",
    "cycl_pos_in_time = encode_1d_to_2d(positions=pos_in_time)\n",
    "cos_pos_in_time = cycl_pos_in_time[:,0]\n",
    "sin_pos_in_time = cycl_pos_in_time[:,1]\n",
    "trial_type_in_time = []\n",
    "trial_group_in_time = []\n",
    "for tn in trial_number_in_time:\n",
    "    trial = beh['trials'][beh['trials']['number'] == tn]\n",
    "    type = trial['type'].iloc[0]\n",
    "    performance = trial['performance'].iloc[0]\n",
    "    context = trial['context'].iloc[0]\n",
    "    group = f'{context}{type}{performance}'\n",
    "    trial_type_in_time.append(type)\n",
    "    trial_group_in_time.append(group)\n",
    "trial_type_in_time = np.array(trial_type_in_time)\n",
    "trial_group_in_time = np.array(trial_group_in_time)\n",
    "\n",
    "# cast b and nb to 0 and 1\n",
    "trial_type_in_time[trial_type_in_time == 'b'] = '0'\n",
    "trial_type_in_time[trial_type_in_time == 'nb'] = '1'\n",
    "\n",
    "all_behaviour = np.stack([pos_in_time, \n",
    "                          cos_pos_in_time, \n",
    "                          sin_pos_in_time, \n",
    "                          trial_type_in_time, \n",
    "                          trial_group_in_time, \n",
    "                          trial_number_in_time, \n",
    "                          time_in_time], axis=0)\n",
    "all_behaviour = np.transpose(all_behaviour)\n",
    "\n",
    "train_mask = all_behaviour[:, 4] == 'rz1bhit'\n",
    "train_mask = all_behaviour[:, 0].astype(np.float64) > 0\n",
    "\n",
    "test_mask = all_behaviour[:, 4] == 'rz1nbhit'\n",
    "label_train = all_behaviour[train_mask]\n",
    "label_test = all_behaviour[test_mask]\n",
    "\n",
    "for i, (cluster_ids, label) in enumerate(zip(cluster_id_groups, cluster_id_labels)):\n",
    "    tcs_array = []\n",
    "    for id in cluster_ids:\n",
    "        tc = tcs_time[id]\n",
    "        tc = gaussian_filter(np.nan_to_num(tc).astype(np.float64), sigma=2.5)\n",
    "        tc = zscore(tc)\n",
    "        tcs_array.append(tc)\n",
    "    tcs_array = np.array(tcs_array)\n",
    "\n",
    "    # Transpose to shape (N, M) for UMAP\n",
    "    data_transposed = tcs_array.T\n",
    "    \n",
    "    max_i = 5000\n",
    "    dims = 32  # here, we set as a variable for hypothesis testing below.\n",
    "\n",
    "    # build behaviour models\n",
    "    position_model = CEBRA(model_architecture='offset10-model',\n",
    "                           batch_size=512, \n",
    "                           learning_rate=3e-4,\n",
    "                           temperature=10, \n",
    "                           output_dimension=dims, \n",
    "                           max_iterations=max_i,\n",
    "                           distance='cosine', \n",
    "                           conditional='time_delta',  \n",
    "                           device='cuda_if_available',\n",
    "                           verbose=True, time_offsets=1)\n",
    "    \n",
    "    position_trial_type_model = CEBRA(model_architecture='offset10-model',\n",
    "                                batch_size=512, \n",
    "                                learning_rate=3e-4,\n",
    "                                temperature=10, \n",
    "                                output_dimension=dims, \n",
    "                                max_iterations=max_i,\n",
    "                                distance='cosine', \n",
    "                                conditional='time_delta',  \n",
    "                                device='cuda_if_available',\n",
    "                                verbose=True, time_offsets=1)\n",
    "    \n",
    "    neural_train = data_transposed[train_mask]\n",
    "    neural_test = data_transposed[test_mask]\n",
    "\n",
    "    # train models\n",
    "    position_model.fit(neural_train, label_train[:, 1:3].astype(float))\n",
    "    position_trial_type_model.fit(neural_train, label_train[:, 1:4].astype(float))\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(position_model.state_dict_['loss'], c='red', alpha=0.3, label='position')\n",
    "    ax.plot(position_trial_type_model.state_dict_['loss'], c='blue', alpha=0.3, label='position+type')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xlabel('Iterations')\n",
    "    ax.set_ylabel('InfoNCE Loss')\n",
    "    plt.legend(bbox_to_anchor=(0.5, 0.3), frameon=False)\n",
    "    plt.show()\n",
    "\n",
    "    #plot embeddings\n",
    "    position_embedding = position_model.transform(neural_train)\n",
    "    position_type_embedding = position_trial_type_model.transform(neural_train)\n",
    "    position_embedding_test = position_model.transform(neural_test)\n",
    "    position_type_embedding_test = position_trial_type_model.transform(neural_test)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax1 = fig.add_subplot(2, 2, 1, projection=\"3d\")\n",
    "    ax2 = fig.add_subplot(2, 2, 2, projection=\"3d\")\n",
    "    ax3 = fig.add_subplot(2, 2, 3, projection=\"3d\")\n",
    "    ax4 = fig.add_subplot(2, 2, 4, projection=\"3d\")\n",
    "    ax1 = plot_embeddings(ax1, position_embedding, pos_in_time[train_mask], cmap=\"track\", viewing_angle=2)\n",
    "    ax2 = plot_embeddings(ax2, position_type_embedding, pos_in_time[train_mask], cmap=\"track\", viewing_angle=2)\n",
    "    ax3 = plot_embeddings(ax3, position_embedding_test, pos_in_time[test_mask], cmap=\"track\", viewing_angle=2)\n",
    "    ax4 = plot_embeddings(ax4, position_type_embedding_test, pos_in_time[test_mask], cmap=\"track\", viewing_angle=2)\n",
    "    ax1.set_title('Position')\n",
    "    ax2.set_title('Position+Type')\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cluster_id_groups=[cluster_ids_by_group[-2], cluster_ids_by_group[-4], vr_ns.cluster_id.values]\n",
    "cluster_id_labels=['GC', 'NGS', 'NS']\n",
    "\n",
    "tcs, tcs_time, autocorrs, last_ephys_bin, beh, clusters = compute_vr_tcs(mouse, day, apply_zscore=False)           \n",
    "trial_groups, trial_colors = get_trial_groups_and_colors(beh, last_ephys_bin, tl, bs)\n",
    "sorted_trial_indices, sorted_trial_colors = get_sorted_trials_and_colors(beh, last_ephys_bin, tl, bs)\n",
    "last_ephys_time_bin = clusters[clusters.index[0]].count(bin_size=time_bs, time_units = 'ms').index[-1]\n",
    "ep = nap.IntervalSet(start=0, end=last_ephys_time_bin, time_units = 's')\n",
    "speed_in_time = beh['S'].bin_average(bin_size=time_bs, time_units = 'ms', ep=ep)\n",
    "dt_in_time = beh['travel'].bin_average(bin_size=time_bs, time_units = 'ms', ep=ep)-((beh['trial_number'][0]-1)*tl)\n",
    "pos_in_time = dt_in_time%tl\n",
    "trial_number_in_time = (dt_in_time//tl)+beh['trial_number'][0]\n",
    "trial_type_in_time = []\n",
    "trial_group_in_time = []\n",
    "for tn in trial_number_in_time:\n",
    "    trial = beh['trials'][beh['trials']['number'] == tn]\n",
    "    type = trial['type'].iloc[0]\n",
    "    performance = trial['performance'].iloc[0]\n",
    "    context = trial['context'].iloc[0]\n",
    "    group = f'{context}{type}{performance}'\n",
    "    trial_type_in_time.append(type)\n",
    "    trial_group_in_time.append(group)\n",
    "trial_type_in_time = np.array(trial_type_in_time)\n",
    "trial_group_in_time = np.array(trial_group_in_time)\n",
    "\n",
    "trial_type_in_time = []\n",
    "trial_group_in_time = []\n",
    "for tn in trial_number_in_time:\n",
    "    trial = beh['trials'][beh['trials']['number'] == tn]\n",
    "    type = trial['type'].iloc[0]\n",
    "    performance = trial['performance'].iloc[0]\n",
    "    context = trial['context'].iloc[0]\n",
    "    group = f'{context}{type}{performance}'\n",
    "    trial_type_in_time.append(type)\n",
    "    trial_group_in_time.append(group)\n",
    "trial_type_in_time = np.array(trial_type_in_time)\n",
    "trial_group_in_time = np.array(trial_group_in_time)\n",
    "\n",
    "moving_mask = speed_in_time > 0\n",
    "trial_group_in_time = trial_group_in_time[moving_mask]\n",
    "trial_type_in_time = trial_type_in_time[moving_mask]\n",
    "pos_in_time = pos_in_time[moving_mask]\n",
    "\n",
    "b_mask = trial_group_in_time == 'rz1bhit'\n",
    "nb_mask = trial_group_in_time == 'rz1nbhit'\n",
    "\n",
    "for i, (cluster_ids, label) in enumerate(zip(cluster_id_groups, cluster_id_labels)):\n",
    "    tcs_array = []\n",
    "    for id in cluster_ids:\n",
    "        tc = tcs_time[id]\n",
    "        tc = gaussian_filter(np.nan_to_num(tc).astype(np.float64), sigma=2.5)\n",
    "        tc = zscore(tc)\n",
    "        tcs_array.append(tc)\n",
    "    tcs_array = np.array(tcs_array)\n",
    "\n",
    "    # Transpose to shape (N, M) for UMAP\n",
    "    data_transposed = tcs_array.T\n",
    "    data_transposed = data_transposed[moving_mask]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    data_normalized = scaler.fit_transform(data_transposed)\n",
    "\n",
    "    reducer = umap.UMAP(n_components=2, random_state=7)\n",
    "    embedding = reducer.fit_transform(data_normalized)\n",
    "\n",
    "    # Plot the 3D embedding\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(embedding[:, 0][b_mask], embedding[:, 1][b_mask], pos_in_time[b_mask], alpha=0.05, color='tab:blue', s=5)\n",
    "    ax.scatter(embedding[:, 0][nb_mask], embedding[:, 1][nb_mask], pos_in_time[nb_mask], alpha=0.05, color='tab:orange', s=5)\n",
    "    ax.set_title('3D UMAP Projection of Neural Data')\n",
    "    ax.set_xlabel('UMAP 1')\n",
    "    ax.set_ylabel('UMAP 2')\n",
    "    ax.set_zlabel('UMAP 3')\n",
    "    ax.view_init(elev=30, azim=45)\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fig, ax = plt.subplots(1,1, figsize=(3,3))\n",
    "\n",
    "for i in range(len(angles1[trial_groups == 'rz1bhit'])):\n",
    "    angles_1_i = angles1[trial_groups == 'rz1bhit'][i]\n",
    "    angles_2_i = angles2[trial_groups == 'rz1bhit'][i]\n",
    "    diff_angles1 = np.append(np.array([0]), np.diff(angles_1_i))\n",
    "    diff_angles2 = np.append(np.array([0]), np.diff(angles_2_i))\n",
    "\n",
    "    # wrapping around correction\n",
    "    diff_angles1[diff_angles1>(0.66*2*np.pi)] = diff_angles1[diff_angles1>(0.66*2*np.pi)]-(2*np.pi)\n",
    "    diff_angles1[diff_angles1<(-0.66*2*np.pi)] = diff_angles1[diff_angles1<(-0.66*2*np.pi)]+(2*np.pi)\n",
    "\n",
    "    diff_angles2[diff_angles2>(0.66*2*np.pi)] = diff_angles2[diff_angles2>(0.66*2*np.pi)]-(2*np.pi)\n",
    "    diff_angles2[diff_angles2<(-0.66*2*np.pi)] = diff_angles2[diff_angles2<(-0.66*2*np.pi)]+(2*np.pi)\n",
    "    \n",
    "    cum_angles1 = np.cumsum(diff_angles1)\n",
    "    cum_angles2 = np.cumsum(diff_angles2)\n",
    "    plt.plot(cum_angles1, cum_angles2, color=\"tab:blue\", alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(3,3))\n",
    "for i in range(len(angles1[trial_groups == 'rz1nbhit'])):\n",
    "    angles_1_i = angles1[trial_groups == 'rz1nbhit'][i]\n",
    "    angles_2_i = angles2[trial_groups == 'rz1nbhit'][i]\n",
    "    diff_angles1 = np.append(np.array([0]), np.diff(angles_1_i))\n",
    "    diff_angles2 = np.append(np.array([0]), np.diff(angles_2_i))\n",
    "\n",
    "    # wrapping around correction\n",
    "    diff_angles1[diff_angles1>(0.66*2*np.pi)] = diff_angles1[diff_angles1>(0.66*2*np.pi)]-(2*np.pi)\n",
    "    diff_angles1[diff_angles1<(-0.66*2*np.pi)] = diff_angles1[diff_angles1<(-0.66*2*np.pi)]+(2*np.pi)\n",
    "\n",
    "    diff_angles2[diff_angles2>(0.66*2*np.pi)] = diff_angles2[diff_angles2>(0.66*2*np.pi)]-(2*np.pi)\n",
    "    diff_angles2[diff_angles2<(-0.66*2*np.pi)] = diff_angles2[diff_angles2<(-0.66*2*np.pi)]+(2*np.pi)\n",
    "    \n",
    "    cum_angles1 = np.cumsum(diff_angles1)\n",
    "    cum_angles2 = np.cumsum(diff_angles2)\n",
    "    plt.plot(cum_angles1, cum_angles2, color=\"tab:orange\",alpha=0.3)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fig, ax = plt.subplots(1,1, figsize=(3,3))\n",
    "\n",
    "for i in range(len(angles1[trial_groups == 'rz1bhit'])):\n",
    "    angles_1_i = angles1[trial_groups == 'rz1bhit'][i]+np.pi\n",
    "    angles_2_i = angles2[trial_groups == 'rz1bhit'][i]+np.pi\n",
    "    plt.plot(angles_1_i, angles_2_i, color=\"tab:blue\", alpha=0.3)\n",
    "\n",
    "for i in range(len(angles1[trial_groups == 'rz1nbhit'])):\n",
    "    angles_1_i = angles1[trial_groups == 'rz1nbhit'][i]+np.pi\n",
    "    angles_2_i = angles2[trial_groups == 'rz1nbhit'][i]+np.pi\n",
    "    plt.plot(angles_1_i, angles_2_i, color=\"tab:orange\", alpha=0.3)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cum_angles1 = np.append(np.array([0]), np.diff(angles1))\n",
    "cum_angles2 = np.append(np.array([0]), np.diff(angles1))\n",
    "\n",
    "plt.hist(cum_angles1,bins=100)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(cum_angles2,bins=100)\n",
    "plt.show()\n",
    "\n",
    "# wrapping around correction\n",
    "cum_angles1[cum_angles1>(0.66*2*np.pi)] = cum_angles1[cum_angles1>(0.66*2*np.pi)]-(2*np.pi)\n",
    "cum_angles1[cum_angles1<(-0.66*2*np.pi)] = cum_angles1[cum_angles1<(-0.66*2*np.pi)]+(2*np.pi)\n",
    "\n",
    "cum_angles2[cum_angles2>(0.66*2*np.pi)] = cum_angles2[cum_angles2>(0.66*2*np.pi)]-(2*np.pi)\n",
    "cum_angles2[cum_angles2<(-0.66*2*np.pi)] = cum_angles2[cum_angles2<(-0.66*2*np.pi)]+(2*np.pi)\n",
    " \n",
    "plt.plot(np.cumsum(cum_angles1))\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(mouse, day, cluster_ids=cluster_ids_by_group[0], figpath=fig_path, label=\"GC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_toroidal_projection(mouse, day, cluster_ids=cluster_ids_by_group[0], figpath=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_rate_maps_with_avg(mouse, day, cluster_ids=cluster_ids_by_group[0], label='GC', figpath=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_rate_maps_with_avg(mouse, day, cluster_ids=cluster_ids_by_group[-4], label='NGS', figpath=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projected_stops(mouse, day, cluster_ids=cluster_ids_by_group[-4], label=\"NGS\", figpath=fig_path)\n",
    "plot_decoding(mouse, day, cluster_ids=cluster_ids_by_group[-4], label=\"NGS\", figpath=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projected_stops(mouse, day, cluster_ids=cluster_ids_by_group[-2], label=\"GC\", figpath=fig_path)\n",
    "plot_decoding(mouse, day, cluster_ids=cluster_ids_by_group[-2], label=\"GC\", figpath=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_decoding(mouse, day, cluster_ids=np.intersect1d(cluster_ids_by_group[-4], rc.cluster_id.values), label=\"NGS_ramp_cells\", figpath=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_decoding(mouse, day, cluster_ids=rc.cluster_id.values, label=\"ramp_cells\", figpath=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare_decodings(mouse, day, cluster_ids_1=cluster_ids_by_group[-2], \n",
    "#                  cluster_ids_2=np.intersect1d(cluster_ids_by_group[-4], rc.cluster_id.values), label1='GC', label2='RC_NGS', figpath=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare_decodings(mouse, day, cluster_ids_1=cluster_ids_by_group[-2], \n",
    "#                  cluster_ids_2=cluster_ids_by_group[-4], label1='GC', label2='NGS', figpath=fig_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
