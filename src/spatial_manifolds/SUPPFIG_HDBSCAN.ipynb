{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pynapple as nap\n",
    "from spatial_manifolds.toroidal import *\n",
    "from spatial_manifolds.behaviour_plots import *\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from scipy.spatial import distance\n",
    "from spatial_manifolds.circular_decoder import circular_decoder, cross_validate_decoder, cross_validate_decoder_time, circular_nanmean\n",
    "\n",
    "from spatial_manifolds.data.curation import curate_clusters\n",
    "from scipy.stats import zscore\n",
    "from spatial_manifolds.util import gaussian_filter_nan\n",
    "from spatial_manifolds.predictive_grid import compute_travel_projected, wrap_list\n",
    "from spatial_manifolds.behaviour_plots import *\n",
    "from spatial_manifolds.behaviour_plots import trial_cat_priority\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hdbscan\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from IPython.display import HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in [20,21,22,25,26,27,28,29]:\n",
    "    for day in np.arange(10,45):\n",
    "        try:\n",
    "            print(mouse, day)\n",
    "            session = 'OF1'\n",
    "            of1_folder = f'/Users/harryclark/Downloads/COHORT12_nwb/M{mouse}/D{day:02}/{session}/'\n",
    "            grid_path = of1_folder + \"tuning_scores/grid_score.parquet\"\n",
    "            shifted_grid_path = of1_folder + \"tuning_scores/shifted_grid_score.parquet\"\n",
    "            spatial_path = of1_folder + \"tuning_scores/shifted_spatial_information.parquet\"\n",
    "            spikes_path = of1_folder + f\"sub-{mouse}_day-{day:02}_ses-{session}_srt-kilosort4_clusters.npz\"\n",
    "            beh_path = of1_folder + f\"sub-{mouse}_day-{day:02}_ses-{session}_beh.nwb\"\n",
    "            active_projects_path = Path(\"/Volumes/cmvm/sbms/groups/CDBS_SIDB_storage/NolanLab/ActiveProjects/\")\n",
    "            anatomy_path = active_projects_path / \"Chris/Cohort12/derivatives/labels/anatomy/cluster_annotations.csv\"\n",
    "            cluster_locations = pd.read_csv(anatomy_path)\n",
    "            beh_OF = nap.load_file(beh_path)\n",
    "            clusters_OF = nap.load_file(spikes_path)\n",
    "            shifted_grid_scores_of1 = pd.read_parquet(shifted_grid_path)\n",
    "            spatial_information_score_of1 = pd.read_parquet(spatial_path)\n",
    "            shifted_grid_scores_of1 = shifted_grid_scores_of1.query('travel >= 0')\n",
    "            spatial_information_score_of1 = spatial_information_score_of1.query('travel >= 0')\n",
    "            cluster_ids_values = shifted_grid_scores_of1.query('travel == 0').cluster_id\n",
    "\n",
    "\n",
    "            percentile_threshold = 99\n",
    "\n",
    "            non_grid_cells = pd.DataFrame()\n",
    "            grid_cells = pd.DataFrame()\n",
    "            non_spatial_cells = pd.DataFrame()\n",
    "            cells = pd.DataFrame()\n",
    "\n",
    "            for index in cluster_ids_values:\n",
    "\n",
    "                cluster_spatial_information_of1 = spatial_information_score_of1[spatial_information_score_of1.cluster_id==index]\n",
    "                cluster_shifted_grid_scores_of1 = shifted_grid_scores_of1[shifted_grid_scores_of1.cluster_id==index]\n",
    "\n",
    "                percentile99_grid_score_of1 = np.nanpercentile(cluster_shifted_grid_scores_of1.null_grid_score.iloc[0], percentile_threshold)\n",
    "                percentile99_spatial_information_of1 = np.nanpercentile(cluster_spatial_information_of1.null_spatial_information.iloc[0], percentile_threshold)\n",
    "\n",
    "                field_spacing = cluster_shifted_grid_scores_of1.field_spacing.values[np.nanargmax(cluster_shifted_grid_scores_of1.grid_score)]\n",
    "                orientation = cluster_shifted_grid_scores_of1.orientation.values[np.nanargmax(cluster_shifted_grid_scores_of1.grid_score)]\n",
    "                \n",
    "                max_grid_score_of1 = cluster_shifted_grid_scores_of1.grid_score.values[np.nanargmax(cluster_shifted_grid_scores_of1.grid_score)]\n",
    "                spatial_info = cluster_spatial_information_of1.spatial_information.values[np.nanargmax(cluster_shifted_grid_scores_of1.grid_score)]\n",
    "                spatial_info_no_lag = cluster_spatial_information_of1.spatial_information.iloc[0]\n",
    "\n",
    "                cell = shifted_grid_scores_of1[shifted_grid_scores_of1.grid_score==max_grid_score_of1]\n",
    "\n",
    "                if (max_grid_score_of1 > percentile99_grid_score_of1) and (spatial_info > percentile99_spatial_information_of1) and (max_grid_score_of1>0.4):\n",
    "                    grid_cells = pd.concat([grid_cells, cell], ignore_index=True)\n",
    "                elif (spatial_info_no_lag > percentile99_spatial_information_of1):\n",
    "                    non_grid_cells = pd.concat([non_grid_cells, cell], ignore_index=True)\n",
    "                else:\n",
    "                    non_spatial_cells = pd.concat([non_spatial_cells, cell], ignore_index=True)\n",
    "                cells = pd.concat([cells, cell], ignore_index=True)\n",
    "                \n",
    "            all_cells = cells.copy()\n",
    "            grid_cells = grid_cells.sort_values(by=['field_spacing'])\n",
    "            non_grid_cells = non_grid_cells.sort_values(by=['field_spacing'])\n",
    "            non_spatial_cells = non_spatial_cells.sort_values(by=['field_spacing'])\n",
    "            non_grid_and_non_spatial_cells = pd.concat([non_grid_cells, non_spatial_cells], ignore_index=True)\n",
    "\n",
    "            print(f'there are {len(non_grid_and_non_spatial_cells)} non_grid and non_spatial_cells')\n",
    "            print(f'there are {len(grid_cells)} grid_cells')\n",
    "            print(f'there are {len(non_grid_cells)} non grid spatial cells')\n",
    "            print(f'there are {len(non_spatial_cells)} non spatial cells')\n",
    "            print(f'there are {len(all_cells)} cells')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            samples = np.stack([np.array(grid_cells['field_spacing']),\n",
    "                                np.cos((np.array(grid_cells['orientation'])/60) * 2 * np.pi),\n",
    "                                np.sin((np.array(grid_cells['orientation'])/60) * 2 * np.pi)]).T\n",
    "\n",
    "            samples2d = np.stack([np.array(grid_cells['field_spacing']),\n",
    "                                np.array(grid_cells['orientation'])]).T\n",
    "\n",
    "            # Standardize the data\n",
    "            scaler = StandardScaler()\n",
    "            samples_scaled = scaler.fit_transform(samples)\n",
    "            samples_scaled[:, 1] /= np.sqrt(2)\n",
    "            samples_scaled[:, 2] /= np.sqrt(2)\n",
    "\n",
    "            samples_scaled = samples\n",
    "\n",
    "            # Apply HDBSCAN\n",
    "            clusterer = hdbscan.HDBSCAN(min_cluster_size=5, cluster_selection_epsilon=3)\n",
    "            module_labels = clusterer.fit_predict(samples_scaled)\n",
    "\n",
    "            # Plot the results\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            label_colors = {label: cm.get_cmap('viridis', len(np.unique(module_labels)))(i) for i, label in enumerate(np.unique(module_labels))}\n",
    "            for mi in np.unique(module_labels):\n",
    "                mask = module_labels == mi\n",
    "                print(f'for mi{mi}, there are {np.sum(mask)} points')\n",
    "                plt.scatter(samples2d[:, 0][mask], samples2d[:, 1][mask], c=label_colors[mi], s=20, cmap='viridis', label='Clustered Points')\n",
    "            # Highlight unassigned points (label -1)\n",
    "            unassigned = samples2d[module_labels == -1]\n",
    "            plt.scatter(unassigned[:, 0], unassigned[:, 1], s=21, color='red', label='Unassigned Points')\n",
    "            plt.scatter(all_cells['field_spacing'], all_cells['orientation'], s=20, color='tab:grey', alpha=0.5,zorder=-1)\n",
    "\n",
    "            #plt.legend()\n",
    "            plt.xlabel('Grid Spacing (cm)')\n",
    "            plt.ylabel('Grid Orientation ($^\\circ$)')\n",
    "            plt.ylim(0,60)\n",
    "            plt.title(f'HDBSCAN M{mouse}D{day}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'/Users/harryclark/Documents/figs/SUPP_Grid_module_classification/HDBSCAN_M{mouse}D{day}.pdf')\n",
    "            plt.show()\n",
    "\n",
    "            if np.unique(module_labels).size == 1 and np.unique(module_labels)[0] == -1:\n",
    "                module_labels[:] = 0  # Assign all points to a single cluster if no clusters were found\n",
    "                label_colors[0] = label_colors[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # put cluster ids into modules then rearange from smallest spacing to larger\n",
    "            grid_module_cluster_ids = []\n",
    "            grid_module_ids = []\n",
    "            avg_spacings = []\n",
    "            for mi, module_label in enumerate(np.unique(module_labels[module_labels != -1])):\n",
    "                grid_ids = np.array(grid_cells['cluster_id'])\n",
    "                cells = grid_cells[np.isin(grid_cells['cluster_id'], grid_ids[module_labels == module_label])]\n",
    "                avg_spacings.append(np.nanmean(cells.field_spacing.values))\n",
    "                grid_module_cluster_ids.append(cells['cluster_id'].tolist())\n",
    "                grid_module_ids.append(mi)\n",
    "                print(f'for module {mi}, there are {len(cells)} cells with average spacing {np.nanmean(cells.field_spacing.values)}')\n",
    "            grid_module_cluster_ids = [x for _, x in sorted(zip(avg_spacings, grid_module_cluster_ids))]\n",
    "            grid_module_ids = [x for _, x in sorted(zip(avg_spacings, grid_module_ids))]\n",
    "\n",
    "                                \n",
    "            ncols = 10\n",
    "            rows_per_module = {mi: int(np.ceil(len(module) / ncols)) for mi, module in zip(grid_module_ids, grid_module_cluster_ids)}\n",
    "            nrows = sum(rows_per_module.values())+len(grid_module_cluster_ids)-1\n",
    "            fig, ax = plt.subplots(ncols=ncols, nrows=nrows, figsize=(10, 1*nrows), squeeze=False)\n",
    "            row_counter = 0\n",
    "            for mi, module_ids in zip(grid_module_ids, grid_module_cluster_ids):\n",
    "                cells = grid_cells[grid_cells['cluster_id'].isin(module_ids)]\n",
    "                print(f'for module {mi}, there are {len(cells)} cells')\n",
    "                counter = 0\n",
    "                for j in range(rows_per_module[mi]):\n",
    "                    for i in range(ncols):\n",
    "                        if counter < len(cells):\n",
    "                            index = cells['cluster_id'].values[counter]\n",
    "                            score = cells['grid_score'].values[counter]\n",
    "                            cluster_shifted_grid_scores = shifted_grid_scores_of1[shifted_grid_scores_of1.cluster_id==index]\n",
    "                            travel = cluster_shifted_grid_scores.travel.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "                            max_score = cluster_shifted_grid_scores.grid_score.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "                            field_spacing = cluster_shifted_grid_scores.field_spacing.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "                            \n",
    "                            tcs = {}    \n",
    "                            position = np.stack([beh_OF['P_x'], beh_OF['P_y']], axis=1)\n",
    "                            beh_lag = compute_travel_projected([\"P_x\", \"P_y\"], position, position, travel)\n",
    "                            position_lagged = np.stack([beh_lag['P_x'], beh_lag['P_y']], axis=1)\n",
    "                            for cell in cells['cluster_id'].values:\n",
    "                                tc = nap.compute_2d_tuning_curves(nap.TsGroup([clusters_OF[cell]]), position_lagged, nb_bins=(40,40))[0]\n",
    "                                tc = gaussian_filter_nan(tc[0], sigma=(2.5,2.5))\n",
    "                                tcs[cell] = tc\n",
    "                            #ax[j, i].text(0,-2, f'id: {index}, mgs: {np.round(max_score, decimals=1)}', size=7)\n",
    "                            #ax[j, i].text(0,44, f'fs:{int(field_spacing)}', size=7)\n",
    "                            ax[row_counter, i].imshow(tcs[index], cmap='jet')\n",
    "                            counter+=1\n",
    "                    row_counter += 1\n",
    "                row_counter += 1\n",
    "\n",
    "            for axi in ax.flatten():\n",
    "                axi.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'/Users/harryclark/Documents/figs/SUPP_Grid_module_classification/GC_rate_maps_modules_M{mouse}D{day}.pdf')\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {mouse} day {day}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
