{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pynapple as nap\n",
    "from spatial_manifolds.toroidal import *\n",
    "from spatial_manifolds.behaviour_plots import *\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from scipy.spatial import distance\n",
    "from spatial_manifolds.circular_decoder import circular_decoder, cross_validate_decoder, cross_validate_decoder_time, circular_nanmean\n",
    "\n",
    "from spatial_manifolds.data.curation import curate_clusters\n",
    "from scipy.stats import zscore\n",
    "from spatial_manifolds.util import gaussian_filter_nan\n",
    "from spatial_manifolds.predictive_grid import compute_travel_projected, wrap_list\n",
    "from spatial_manifolds.behaviour_plots import *\n",
    "from spatial_manifolds.behaviour_plots import trial_cat_priority\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from IPython.display import HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = 25\n",
    "day =  25\n",
    "\n",
    "session = 'OF1'\n",
    "of1_folder = f'/Users/harryclark/Downloads/COHORT12_nwb/M{mouse}/D{day:02}/{session}/'\n",
    "grid_path = of1_folder + \"tuning_scores/grid_score.parquet\"\n",
    "shifted_grid_path = of1_folder + \"tuning_scores/shifted_grid_score.parquet\"\n",
    "spatial_path = of1_folder + \"tuning_scores/shifted_spatial_information.parquet\"\n",
    "spikes_path = of1_folder + f\"sub-{mouse}_day-{day:02}_ses-{session}_srt-kilosort4_clusters.npz\"\n",
    "beh_path = of1_folder + f\"sub-{mouse}_day-{day:02}_ses-{session}_beh.nwb\"\n",
    "active_projects_path = Path(\"/Volumes/cmvm/sbms/groups/CDBS_SIDB_storage/NolanLab/ActiveProjects/\")\n",
    "anatomy_path = active_projects_path / \"Chris/Cohort12/derivatives/labels/anatomy/cluster_annotations.csv\"\n",
    "cluster_locations = pd.read_csv(anatomy_path)\n",
    "beh_OF = nap.load_file(beh_path)\n",
    "clusters_OF = nap.load_file(spikes_path)\n",
    "shifted_grid_scores_of1 = pd.read_parquet(shifted_grid_path)\n",
    "spatial_information_score_of1 = pd.read_parquet(spatial_path)\n",
    "\n",
    "shifted_grid_scores_of1 = shifted_grid_scores_of1.query('travel >= 0')\n",
    "spatial_information_score_of1 = spatial_information_score_of1.query('travel >= 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ids_values = shifted_grid_scores_of1.query('travel == 0').cluster_id\n",
    "\n",
    "non_grid_cells = pd.DataFrame()\n",
    "grid_cells = pd.DataFrame()\n",
    "non_spatial_cells = pd.DataFrame()\n",
    "cells = pd.DataFrame()\n",
    "\n",
    "for index in cluster_ids_values:\n",
    "\n",
    "    cluster_spatial_information_of1 = spatial_information_score_of1[spatial_information_score_of1.cluster_id==index]\n",
    "    cluster_shifted_grid_scores_of1 = shifted_grid_scores_of1[shifted_grid_scores_of1.cluster_id==index]\n",
    "\n",
    "    percentile99_grid_score_of1 = np.nanpercentile(cluster_shifted_grid_scores_of1.null_grid_score.iloc[0], 95)\n",
    "    percentile99_spatial_information_of1 = np.nanpercentile(cluster_spatial_information_of1.null_spatial_information.iloc[0], 95)\n",
    "\n",
    "    field_spacing = cluster_shifted_grid_scores_of1.field_spacing.values[np.nanargmax(cluster_shifted_grid_scores_of1.grid_score)]\n",
    "    orientation = cluster_shifted_grid_scores_of1.orientation.values[np.nanargmax(cluster_shifted_grid_scores_of1.grid_score)]\n",
    "    \n",
    "    max_grid_score_of1 = cluster_shifted_grid_scores_of1.grid_score.values[np.nanargmax(cluster_shifted_grid_scores_of1.grid_score)]\n",
    "    spatial_info = cluster_spatial_information_of1.spatial_information.values[np.nanargmax(cluster_shifted_grid_scores_of1.grid_score)]\n",
    "    spatial_info_no_lag = cluster_spatial_information_of1.spatial_information.iloc[0]\n",
    "\n",
    "    cell = shifted_grid_scores_of1[shifted_grid_scores_of1.grid_score==max_grid_score_of1]\n",
    "\n",
    "    if (max_grid_score_of1 > percentile99_grid_score_of1) and (spatial_info > percentile99_spatial_information_of1) and (max_grid_score_of1>0.4):\n",
    "        grid_cells = pd.concat([grid_cells, cell], ignore_index=True)\n",
    "    elif (spatial_info_no_lag > percentile99_spatial_information_of1):\n",
    "        non_grid_cells = pd.concat([non_grid_cells, cell], ignore_index=True)\n",
    "    else:\n",
    "        non_spatial_cells = pd.concat([non_spatial_cells, cell], ignore_index=True)\n",
    "    cells = pd.concat([cells, cell], ignore_index=True)\n",
    "    \n",
    "all_cells = cells.copy()\n",
    "grid_cells = grid_cells.sort_values(by=['field_spacing'])\n",
    "non_grid_cells = non_grid_cells.sort_values(by=['field_spacing'])\n",
    "non_spatial_cells = non_spatial_cells.sort_values(by=['field_spacing'])\n",
    "non_grid_and_non_spatial_cells = pd.concat([non_grid_cells, non_spatial_cells], ignore_index=True)\n",
    "\n",
    "print(f'there are {len(non_grid_and_non_spatial_cells)} non_grid and non_spatial_cells')\n",
    "print(f'there are {len(grid_cells)} grid_cells')\n",
    "print(f'there are {len(non_grid_cells)} non grid spatial cells')\n",
    "print(f'there are {len(non_spatial_cells)} non spatial cells')\n",
    "print(f'there are {len(all_cells)} cells')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(grid_cells['field_spacing'], grid_cells['orientation'], color='tab:red')\n",
    "plt.scatter(non_grid_cells['field_spacing'], non_grid_cells['orientation'], color='tab:cyan')\n",
    "plt.scatter(non_spatial_cells['field_spacing'], non_spatial_cells['orientation'], color='tab:grey', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hdbscan\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "samples = np.stack([np.array(grid_cells['field_spacing']),\n",
    "                    np.cos((np.array(grid_cells['orientation'])/60) * 2 * np.pi),\n",
    "                    np.sin((np.array(grid_cells['orientation'])/60) * 2 * np.pi)]).T\n",
    "\n",
    "samples2d = np.stack([np.array(grid_cells['field_spacing']),\n",
    "                    np.array(grid_cells['orientation'])]).T\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "samples_scaled = scaler.fit_transform(samples)\n",
    "samples_scaled[:, 1] /= np.sqrt(2)\n",
    "samples_scaled[:, 2] /= np.sqrt(2)\n",
    "\n",
    "samples_scaled = samples\n",
    "\n",
    "# Apply HDBSCAN\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, cluster_selection_epsilon=3)\n",
    "module_labels = clusterer.fit_predict(samples_scaled)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(3, 3))\n",
    "label_colors = {label: cm.get_cmap('viridis', len(np.unique(module_labels)))(i) for i, label in enumerate(np.unique(module_labels))}\n",
    "for mi in np.unique(module_labels):\n",
    "    mask = module_labels == mi\n",
    "    print(f'for mi{mi}, there are {np.sum(mask)} points')\n",
    "    plt.scatter(samples2d[:, 0][mask], samples2d[:, 1][mask], c=label_colors[mi], s=20, cmap='viridis', label='Clustered Points')\n",
    "# Highlight unassigned points (label -1)\n",
    "unassigned = samples2d[module_labels == -1]\n",
    "plt.scatter(unassigned[:, 0], unassigned[:, 1], s=21, color='red', label='Unassigned Points')\n",
    "plt.scatter(all_cells['field_spacing'], all_cells['orientation'], s=20, color='tab:grey', alpha=0.5,zorder=-1)\n",
    "\n",
    "#plt.legend()\n",
    "plt.xlabel('Grid Spacing (cm)')\n",
    "plt.ylabel('Grid Orientation ($^\\circ$)')\n",
    "plt.ylim(0,60)\n",
    "plt.title(f'HDBSCAN M{mouse}D{day}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/SUPP_Grid_module_classification/HDBSCAN_M{mouse}D{day}.pdf')\n",
    "plt.show()\n",
    "\n",
    "if np.unique(module_labels).size == 1 and np.unique(module_labels)[0] == -1:\n",
    "    module_labels[:] = 0  # Assign all points to a single cluster if no clusters were found\n",
    "    label_colors[0] = label_colors[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put cluster ids into modules then rearange from smallest spacing to larger\n",
    "grid_module_cluster_ids = []\n",
    "grid_module_ids = []\n",
    "avg_spacings = []\n",
    "for mi, module_label in enumerate(np.unique(module_labels[module_labels != -1])):\n",
    "    grid_ids = np.array(grid_cells['cluster_id'])\n",
    "    cells = grid_cells[np.isin(grid_cells['cluster_id'], grid_ids[module_labels == module_label])]\n",
    "    avg_spacings.append(np.nanmean(cells.field_spacing.values))\n",
    "    grid_module_cluster_ids.append(cells['cluster_id'].tolist())\n",
    "    grid_module_ids.append(mi)\n",
    "    print(f'for module {mi}, there are {len(cells)} cells with average spacing {np.nanmean(cells.field_spacing.values)}')\n",
    "grid_module_cluster_ids = [x for _, x in sorted(zip(avg_spacings, grid_module_cluster_ids))]\n",
    "grid_module_ids = [x for _, x in sorted(zip(avg_spacings, grid_module_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 10\n",
    "rows_per_module = {mi: int(np.ceil(len(module) / ncols)) for mi, module in zip(grid_module_ids, grid_module_cluster_ids)}\n",
    "nrows = sum(rows_per_module.values())+len(grid_module_cluster_ids)-1\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, figsize=(10, 1*nrows), squeeze=False)\n",
    "row_counter = 0\n",
    "for mi, module_ids in zip(grid_module_ids, grid_module_cluster_ids):\n",
    "    cells = grid_cells[grid_cells['cluster_id'].isin(module_ids)]\n",
    "    print(f'for module {mi}, there are {len(cells)} cells')\n",
    "    counter = 0\n",
    "    for j in range(rows_per_module[mi]):\n",
    "        for i in range(ncols):\n",
    "            if counter < len(cells):\n",
    "                index = cells['cluster_id'].values[counter]\n",
    "                score = cells['grid_score'].values[counter]\n",
    "                cluster_shifted_grid_scores = shifted_grid_scores_of1[shifted_grid_scores_of1.cluster_id==index]\n",
    "                travel = cluster_shifted_grid_scores.travel.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "                max_score = cluster_shifted_grid_scores.grid_score.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "                field_spacing = cluster_shifted_grid_scores.field_spacing.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "                \n",
    "                tcs = {}    \n",
    "                position = np.stack([beh_OF['P_x'], beh_OF['P_y']], axis=1)\n",
    "                beh_lag = compute_travel_projected([\"P_x\", \"P_y\"], position, position, travel)\n",
    "                position_lagged = np.stack([beh_lag['P_x'], beh_lag['P_y']], axis=1)\n",
    "                for cell in cells['cluster_id'].values:\n",
    "                    tc = nap.compute_2d_tuning_curves(nap.TsGroup([clusters_OF[cell]]), position_lagged, nb_bins=(40,40))[0]\n",
    "                    tc = gaussian_filter_nan(tc[0], sigma=(2.5,2.5))\n",
    "                    tcs[cell] = tc\n",
    "                #ax[j, i].text(0,-2, f'id: {index}, mgs: {np.round(max_score, decimals=1)}', size=7)\n",
    "                #ax[j, i].text(0,44, f'fs:{int(field_spacing)}', size=7)\n",
    "                ax[row_counter, i].imshow(tcs[index], cmap='jet')\n",
    "                counter+=1\n",
    "        row_counter += 1\n",
    "    row_counter += 1\n",
    "\n",
    "for axi in ax.flatten():\n",
    "    axi.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/SUPP_Grid_module_classification/GC_rate_maps_modules_M{mouse}D{day}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ncols = 10\n",
    "nrows = int(np.ceil(len(non_grid_and_non_spatial_cells) / ncols))\n",
    "\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, figsize=(10, 1*nrows), squeeze=False)\n",
    "cells = non_grid_and_non_spatial_cells\n",
    "counter = 0\n",
    "for j in range(nrows):\n",
    "    for i in range(ncols):\n",
    "        if counter < len(cells):\n",
    "            index = cells['cluster_id'].values[counter]\n",
    "            score = cells['grid_score'].values[counter]\n",
    "            cluster_shifted_grid_scores = shifted_grid_scores_of1[shifted_grid_scores_of1.cluster_id==index]\n",
    "            travel = cluster_shifted_grid_scores.travel.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "            max_score = cluster_shifted_grid_scores.grid_score.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "            field_spacing = cluster_shifted_grid_scores.field_spacing.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "            \n",
    "            tcs = {}    \n",
    "            position = np.stack([beh_OF['P_x'], beh_OF['P_y']], axis=1)\n",
    "            beh_lag = compute_travel_projected([\"P_x\", \"P_y\"], position, position, travel)\n",
    "            position_lagged = np.stack([beh_lag['P_x'], beh_lag['P_y']], axis=1)\n",
    "            for cell in cells['cluster_id'].values:\n",
    "                tc = nap.compute_2d_tuning_curves(nap.TsGroup([clusters_OF[cell]]), position_lagged, nb_bins=(40,40))[0]\n",
    "                tc = gaussian_filter_nan(tc[0], sigma=(2.5,2.5))\n",
    "                tcs[cell] = tc\n",
    "            #ax[j, i].text(0,-2, f'id: {index}, mgs: {np.round(max_score, decimals=1)}', size=7)\n",
    "            #ax[j, i].text(0,44, f'fs:{int(field_spacing)}', size=7)\n",
    "            ax[j, i].imshow(tcs[index], cmap='jet')\n",
    "            counter+=1\n",
    "\n",
    "for axi in ax.flatten():\n",
    "    axi.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/SUPP_Grid_module_classification/NGS_NS_rate_maps_module{mi}_{mouse}D{day}_lagged.pdf')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ncols = 10\n",
    "nrows = int(np.ceil(len(non_grid_and_non_spatial_cells) / ncols))\n",
    "\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, figsize=(10, 1*nrows), squeeze=False)\n",
    "cells = non_grid_and_non_spatial_cells\n",
    "counter = 0\n",
    "for j in range(nrows):\n",
    "    for i in range(ncols):\n",
    "        if counter < len(cells):\n",
    "            index = cells['cluster_id'].values[counter]\n",
    "            score = cells['grid_score'].values[counter]\n",
    "            cluster_shifted_grid_scores = shifted_grid_scores_of1[shifted_grid_scores_of1.cluster_id==index]\n",
    "            travel = cluster_shifted_grid_scores.travel.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "            max_score = cluster_shifted_grid_scores.grid_score.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "            field_spacing = cluster_shifted_grid_scores.field_spacing.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "            \n",
    "            tcs = {}    \n",
    "            position = np.stack([beh_OF['P_x'], beh_OF['P_y']], axis=1)\n",
    "            beh_lag = compute_travel_projected([\"P_x\", \"P_y\"], position, position, travel=0)\n",
    "            position_lagged = np.stack([beh_lag['P_x'], beh_lag['P_y']], axis=1)\n",
    "            for cell in cells['cluster_id'].values:\n",
    "                tc = nap.compute_2d_tuning_curves(nap.TsGroup([clusters_OF[cell]]), position_lagged, nb_bins=(40,40))[0]\n",
    "                tc = gaussian_filter_nan(tc[0], sigma=(2.5,2.5))\n",
    "                tcs[cell] = tc\n",
    "            #ax[j, i].text(0,-2, f'id: {index}, mgs: {np.round(max_score, decimals=1)}', size=7)\n",
    "            #ax[j, i].text(0,44, f'fs:{int(field_spacing)}', size=7)\n",
    "            ax[j, i].imshow(tcs[index], cmap='jet')\n",
    "            counter+=1\n",
    "\n",
    "for axi in ax.flatten():\n",
    "    axi.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/SUPP_Grid_module_classification/NGS_NS_rate_maps_module{mi}_{mouse}D{day}_not_lagged.pdf')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now have seperated cells into grid modules and non grid cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_folder = f'/Users/harryclark/Downloads/COHORT12_nwb/M{mouse}/D{day:02}/VR/'\n",
    "spikes_path = vr_folder + f\"sub-{mouse}_day-{day:02}_ses-VR_srt-kilosort4_clusters.npz\"\n",
    "beh_path = vr_folder + f\"sub-{mouse}_day-{day:02}_ses-VR_beh.nwb\"\n",
    "beh = nap.load_file(beh_path)\n",
    "clusters = nap.load_file(spikes_path)\n",
    "clusters = curate_clusters(clusters)\n",
    "\n",
    "tl=200 # cm\n",
    "bs=2 # cm\n",
    "time_bs = 100 # ms\n",
    "tns = beh['trial_number']\n",
    "dt = beh['travel']-((tns[0]-1)*tl)\n",
    "n_bins = int(int(((np.ceil(np.nanmax(dt))//tl)+1)*tl)/bs)\n",
    "max_bound = int(((np.ceil(np.nanmax(dt))//tl)+1)*tl)\n",
    "min_bound = 0\n",
    "dt_bins =np.arange(0,max_bound,bs)\n",
    "plot_stops(beh, tl=200, sort=False, return_fig=False, \n",
    "           savepath=f'/Users/harryclark/Documents/figs/toroidal/M{mouse}D{day}_stops.pdf')\n",
    "plt.close()\n",
    "plot_stops(beh, tl=200, sort=True, return_fig=False, \n",
    "           savepath=f'/Users/harryclark/Documents/figs/toroidal/M{mouse}D{day}_stops_sorted.pdf')\n",
    "plt.close()\n",
    "\n",
    "# trick to clip the tc to around the end of the ephys recording\n",
    "# take the cell with the highest firing rate, and find the last bin with a spike\n",
    "# then work backwards and clip at the end of the last appropriate trials\n",
    "tc = nap.compute_1d_tuning_curves(nap.TsGroup([clusters[clusters.index[np.nanargmax(clusters.firing_rate)]]]), \n",
    "                                      dt, \n",
    "                                      nb_bins=n_bins, \n",
    "                                      minmax=[min_bound, max_bound],\n",
    "                                      ep=beh[\"moving\"])[0]\n",
    "mask = np.isnan(tc)\n",
    "tc = gaussian_filter(np.nan_to_num(tc).astype(np.float64), sigma=2.5)\n",
    "last_ephys_bin = int(np.nonzero(tc)[0][-1] + (tl/bs) - np.nonzero(tc)[0][-1]%(tl/bs))\n",
    "last_ephys_time_bin = clusters[clusters.index[0]].count(bin_size=time_bs, time_units = 'ms').index[-1]\n",
    "\n",
    "# time binned variables for later\n",
    "ep = nap.IntervalSet(start=0, end=last_ephys_time_bin, time_units = 's')\n",
    "speed_in_time = beh['S'].bin_average(bin_size=time_bs, time_units = 'ms', ep=ep)\n",
    "dt_in_time = beh['travel'].bin_average(bin_size=time_bs, time_units = 'ms', ep=ep)-((tns[0]-1)*tl)\n",
    "pos_in_time = dt_in_time%tl\n",
    "trial_number_in_time = (dt_in_time//tl)+tns[0]\n",
    "tcs = {}\n",
    "tcs_time = {}\n",
    "autocorrs = {}\n",
    "for cell in clusters.index:\n",
    "    tc = nap.compute_1d_tuning_curves(nap.TsGroup([clusters[cell]]), \n",
    "                                      dt, \n",
    "                                      nb_bins=n_bins, \n",
    "                                      minmax=[min_bound, max_bound],\n",
    "                                      ep=beh[\"moving\"])[0]\n",
    "    mask = np.isnan(tc)\n",
    "    tc = gaussian_filter(np.nan_to_num(tc).astype(np.float64), sigma=2.5)\n",
    "    tc = zscore(tc)\n",
    "    tc = tc[:last_ephys_bin] # only want bins with ephys data in it\n",
    "    tcs[cell] = tc\n",
    "    \n",
    "    tc_time = clusters[cell].count(bin_size=time_bs, time_units = 'ms', ep=ep)\n",
    "    tc_time = gaussian_filter(np.nan_to_num(tc_time).astype(np.float64), sigma=2.5) # \n",
    "    tc_time = zscore(tc_time)\n",
    "    tcs_time[cell] = tc_time\n",
    "\n",
    "    lags = np.arange(0, 200, 1) # were looking at 10 timesteps back and 10 forward\n",
    "    autocorr = []\n",
    "    for lag in lags:\n",
    "        if lag < 0:\n",
    "            tc_offset = np.roll(tc, lag)\n",
    "            tc_offset[lag:] = 0\n",
    "        elif lag > 0:\n",
    "            tc_offset = np.roll(tc, lag)\n",
    "            tc_offset[:lag] = 0\n",
    "        else:\n",
    "            tc_offset = tc\n",
    "        corr = stats.pearsonr(tc, tc_offset)[0]\n",
    "        autocorr.append(corr)\n",
    "    autocorr = np.array(autocorr)\n",
    "    autocorrs[cell] = autocorr\n",
    "\n",
    "# drop beh trials from after last ephys bin\n",
    "beh_trials = beh['trials']\n",
    "beh_trials = beh_trials[:int(last_ephys_bin/(tl/bs))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "for mi, module_ids in zip(grid_module_ids, grid_module_cluster_ids):\n",
    "    matrix = np.array(list(autocorrs.values()))\n",
    "    matrix_cluster_ids = np.array(list(autocorrs.keys()))\n",
    "    cluster_id_of_interest = module_ids\n",
    "    matrix = matrix[np.isin(matrix_cluster_ids, cluster_id_of_interest)]\n",
    "    matrix_cluster_ids = matrix_cluster_ids[np.isin(matrix_cluster_ids, cluster_id_of_interest)]\n",
    "    peaks = []\n",
    "    for array in matrix:\n",
    "        if len(find_peaks(array)[0])>0:\n",
    "            peak = find_peaks(array)[0][0]\n",
    "        else:\n",
    "            peak = np.nan\n",
    "        peaks.append(peak)\n",
    "    peaks = np.array(peaks)*bs\n",
    "    median_peak = np.nanmedian(peaks)\n",
    "    fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(2,2), squeeze=False)\n",
    "    if median_peak < 200:\n",
    "        max_r = 200\n",
    "    else:\n",
    "        max_r = 400\n",
    "    ax[0,0].hist(peaks, bins=25, range=(0, max_r), color=label_colors[mi])\n",
    "    ax[0,0].axvline(median_peak-15, color='grey', linestyle='--')\n",
    "    ax[0,0].axvline(median_peak+15, color='grey', linestyle='--')\n",
    "    plt.savefig(f'/Users/harryclark/Documents/figs/SUPP_Grid_module_classification/GC_peaks_{mi}_{mouse}D{day}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    for peak, cluster_id in zip(peaks, matrix_cluster_ids):\n",
    "        if not np.abs(peak-median_peak)<20: # 20cm tolerance\n",
    "            module_ids.remove(cluster_id)\n",
    "    grid_module_cluster_ids[grid_module_ids.index(mi)] = module_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 10\n",
    "rows_per_module = {mi: int(np.ceil(len(module) / ncols)) for mi, module in zip(grid_module_ids, grid_module_cluster_ids)}\n",
    "nrows = sum(rows_per_module.values())+len(grid_module_cluster_ids)-1\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, figsize=(10, 1*nrows), squeeze=False)\n",
    "row_counter = 0\n",
    "for mi, module_ids in zip(grid_module_ids, grid_module_cluster_ids):\n",
    "    cells = grid_cells[grid_cells['cluster_id'].isin(module_ids)]\n",
    "    print(f'for module {mi}, there are {len(cells)} cells')\n",
    "    counter = 0\n",
    "    for j in range(rows_per_module[mi]):\n",
    "        for i in range(ncols):\n",
    "            if counter < len(cells):\n",
    "                index = cells['cluster_id'].values[counter]\n",
    "                score = cells['grid_score'].values[counter]\n",
    "                cluster_shifted_grid_scores = shifted_grid_scores_of1[shifted_grid_scores_of1.cluster_id==index]\n",
    "                travel = cluster_shifted_grid_scores.travel.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "                max_score = cluster_shifted_grid_scores.grid_score.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "                field_spacing = cluster_shifted_grid_scores.field_spacing.values[np.nanargmax(cluster_shifted_grid_scores.grid_score)]\n",
    "                \n",
    "                tcs_post_curation = {}    \n",
    "                position = np.stack([beh_OF['P_x'], beh_OF['P_y']], axis=1)\n",
    "                beh_lag = compute_travel_projected([\"P_x\", \"P_y\"], position, position, travel)\n",
    "                position_lagged = np.stack([beh_lag['P_x'], beh_lag['P_y']], axis=1)\n",
    "                for cell in cells['cluster_id'].values:\n",
    "                    tc = nap.compute_2d_tuning_curves(nap.TsGroup([clusters_OF[cell]]), position_lagged, nb_bins=(40,40))[0]\n",
    "                    tc = gaussian_filter_nan(tc[0], sigma=(2.5,2.5))\n",
    "                    tcs_post_curation[cell] = tc\n",
    "                #ax[j, i].text(0,-2, f'id: {index}, mgs: {np.round(max_score, decimals=1)}', size=7)\n",
    "                #ax[j, i].text(0,44, f'fs:{int(field_spacing)}', size=7)\n",
    "                ax[row_counter, i].imshow(tcs_post_curation[index], cmap='jet')\n",
    "                counter+=1\n",
    "        row_counter += 1\n",
    "    row_counter += 1\n",
    "\n",
    "for axi in ax.flatten():\n",
    "    axi.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/SUPP_Grid_module_classification/GC_rate_maps_modules_M{mouse}D{day}_post_curated.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "for mi, module_ids in zip(grid_module_ids, grid_module_cluster_ids):\n",
    "    matrix = np.array(list(autocorrs.values()))\n",
    "    matrix_cluster_ids = np.array(list(autocorrs.keys()))\n",
    "    cluster_id_of_interest = module_ids\n",
    "    matrix = matrix[np.isin(matrix_cluster_ids, cluster_id_of_interest)]\n",
    "    matrix_cluster_ids = matrix_cluster_ids[np.isin(matrix_cluster_ids, cluster_id_of_interest)]\n",
    "    peaks = []\n",
    "    for array in matrix:\n",
    "        if len(find_peaks(array)[0])>0:\n",
    "            peak = find_peaks(array)[0][0]\n",
    "        else:\n",
    "            peak = np.nan\n",
    "        peaks.append(peak)\n",
    "    peaks = np.array(peaks)*bs\n",
    "    median_peak = np.nanmedian(peaks)\n",
    "    fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(2,2), squeeze=False)\n",
    "    if median_peak < 200:\n",
    "        max_r = 200\n",
    "    else:\n",
    "        max_r = 400\n",
    "    ax[0,0].hist(peaks, bins=25, range=(0, max_r), color=label_colors[mi])\n",
    "    ax[0,0].axvline(median_peak-15, color='grey', linestyle='--')\n",
    "    ax[0,0].axvline(median_peak+15, color='grey', linestyle='--')\n",
    "    plt.savefig(f'/Users/harryclark/Documents/figs/SUPP_Grid_module_classification/GC_peaks_{mi}_{mouse}D{day}_post_curated.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now have cluster ids classified into modules, non grid spatial cells and non spatial cells \n",
    "# as defined by activity in the open field\n",
    "grid_module_cluster_ids = sorted(grid_module_cluster_ids, key=len, reverse=True) \n",
    "\n",
    "cluster_ids_by_group = []\n",
    "cluster_ids_by_group.extend(grid_module_cluster_ids)\n",
    "cluster_ids_by_group.append(non_grid_cells.cluster_id.values.tolist())\n",
    "cluster_ids_by_group.append(non_spatial_cells.cluster_id.values.tolist())\n",
    "\n",
    "for cluster_ids in cluster_ids_by_group:\n",
    "    print(cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a hack to remove very low rates \n",
    "new_cluster_ids_by_group = []\n",
    "for cluster_id_group in cluster_ids_by_group:\n",
    "    new_group = []\n",
    "    for cell in cluster_id_group:\n",
    "        rate = nap.TsGroup([clusters[cell]]).rates[0]\n",
    "        if rate < 1:\n",
    "            print(f'{cell} removed for having a very low rate')\n",
    "        else:\n",
    "            new_group.append(cell)\n",
    "    new_cluster_ids_by_group.append(new_group)\n",
    "cluster_ids_by_group = new_cluster_ids_by_group.copy()\n",
    "\n",
    "for cluster_ids in cluster_ids_by_group:\n",
    "    print(cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, cluster_id_group in enumerate(cluster_ids_by_group):\n",
    "    ncols = 10\n",
    "    nrows = int(np.ceil(len(cluster_id_group)/ncols))\n",
    "    fig, ax = plt.subplots(ncols=ncols, nrows=nrows, figsize=(10, 1.4*nrows), squeeze=False)\n",
    "    counter = 0\n",
    "    for j in range(nrows):\n",
    "        for i in range(ncols):\n",
    "            if counter<len(cluster_id_group):\n",
    "                index = cluster_id_group[counter]\n",
    "                plot_firing_rate_map(ax[j, i], \n",
    "                                    zscore(tcs[index]),\n",
    "                                    bs=bs,\n",
    "                                    tl=tl,\n",
    "                                    p=95)\n",
    "            else:\n",
    "                ax[j, i].axis('off')\n",
    "            counter+=1\n",
    "            ax[j, i].set_xticks([])\n",
    "            ax[j, i].set_yticks([])\n",
    "            ax[j, i].xaxis.set_tick_params(labelbottom=False)\n",
    "            ax[j, i].yaxis.set_tick_params(labelleft=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'/Users/harryclark/Documents/figs/SUPP_Grid_module_classification/VR_rate_maps_{m}_M{mouse}D{day}.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcs_to_use = {cluster_id: tcs[cluster_id] for cluster_id in cluster_ids_by_group[0] if cluster_id in tcs}\n",
    "tcs_time_to_use =  {cluster_id: tcs_time[cluster_id] for cluster_id in cluster_ids_by_group[0] if cluster_id in tcs_time}\n",
    "zmaps_time = np.array(list(tcs_time_to_use.values()))\n",
    "\n",
    "N = len(tcs_to_use)\n",
    "zmaps = np.array(list(tcs_to_use.values()))\n",
    "results = spectral_analysis(tcs_to_use, tl, bs=bs)\n",
    "f_modules =              results[0]\n",
    "phi_modules =            results[1]\n",
    "grid_cell_idxs_modules = results[2]\n",
    "spectrograms =           results[3]\n",
    "trial_starts =           results[6]\n",
    "L = tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PSDs\n",
    "plt.figure(figsize=(3,4))\n",
    "nongrid_idxs = np.setdiff1d(np.arange(N), np.concatenate(grid_cell_idxs_modules))\n",
    "fmax = 8/L\n",
    "count = 0\n",
    "Ps = []\n",
    "for j in range(len(grid_cell_idxs_modules)):\n",
    "    grid_cell_idxs = grid_cell_idxs_modules[j]\n",
    "    for gi in grid_cell_idxs:\n",
    "        mp = gaussian_filter1d(zmaps[gi].ravel(), 3)\n",
    "        f, Pxx = welch(mp,nperseg=4000,noverlap=3000)\n",
    "        # Ps.append(Pxx[f<fmax])\n",
    "        Ps.append(Pxx[f<fmax]/(Pxx[f<fmax]).sum())\n",
    "    count += len(grid_cell_idxs)\n",
    "    plt.axhline(count, c='grey',linestyle='dashed',linewidth=0.4)\n",
    "for ngi in nongrid_idxs:\n",
    "    mp = gaussian_filter1d(zmaps[ngi].ravel(), 3)\n",
    "    f, Pxx = welch(mp,nperseg=4000,noverlap=3000)\n",
    "    Ps.append(Pxx[f<fmax]/(Pxx[f<fmax]).sum())\n",
    "Ps = np.stack(Ps)\n",
    "\n",
    "plt.pcolormesh(100*f[f<fmax]/2,np.arange(len(Ps)),np.stack(Ps),vmax=0.04)\n",
    "plt.xlabel(f'Frequency (m-1)')\n",
    "plt.xlim([0,2])\n",
    "plt.ylabel('Neuron')\n",
    "plt.tight_layout()\n",
    "plt.title('PSDs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module spectrograms\n",
    "plt.figure(figsize=(20,3))\n",
    "mi = 2\n",
    "for i, grid_cell_idxs in enumerate(grid_cell_idxs_modules):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    Ng = len(grid_cell_idxs)\n",
    "    S = spectrograms[grid_cell_idxs].mean(0)\n",
    "    plt.imshow(S,origin='lower',aspect='auto',vmax=0.25,cmap='magma')\n",
    "    plt.yticks([0, len(S)/2, len(S)], [0, 1, 2])\n",
    "    \n",
    "    if i==0:\n",
    "        plt.ylabel(f'Frequency (m-1)')\n",
    "\n",
    "    for i in range(1,8):\n",
    "        plt.axhline(100*i/L/2,linewidth=1,c='grey',alpha=0.5)\n",
    "        \n",
    "    for ts in trial_starts[1:-1]:\n",
    "        plt.axvline(ts,linewidth=1,c='grey',alpha=0.5)\n",
    "    plt.xlabel('Trials')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trajectories on the neural sheet\n",
    "grid_cell_idxs = grid_cell_idxs_modules[0]\n",
    "phi = phi_modules[0]\n",
    "Ng = len(grid_cell_idxs)\n",
    "\n",
    "maps = gaussian_filter1d(zmaps[grid_cell_idxs].reshape(Ng, -1), 2, axis=1)\n",
    "maps_time = gaussian_filter1d(zmaps_time[grid_cell_idxs], 2)\n",
    "\n",
    "# maps = zmaps[grid_cell_idxs].reshape(Ng,-1)\n",
    "angles = np.arctan2(np.cos(phi)@maps, np.sin(phi)@maps)\n",
    "angles_time = np.arctan2(np.cos(phi)@maps_time, np.sin(phi)@maps_time)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(10, 5), squeeze=False)\n",
    "\n",
    "ax[0,0].set_title(r'$\\theta_1$')\n",
    "ax[0,0].imshow(angles[0].reshape(-1,int(L/bs)),cmap='hsv')\n",
    "for ts in trial_starts[1:-1]:\n",
    "    ax[0,0].axhline(ts,color='k',linestyle='dashed',linewidth=1)\n",
    "ax[0,0].set_xlabel('Pos. (cm)')\n",
    "ax[0,0].set_ylabel('Trial')\n",
    "\n",
    "ax[0,1].imshow(angles[1].reshape(-1,int(L/bs)),cmap='hsv')\n",
    "ax[0,1].set_title(r'$\\theta_2$')\n",
    "for ts in trial_starts[1:-1]:\n",
    "    ax[0,1].axhline(ts,color='k',linestyle='dashed',linewidth=1)\n",
    "ax[0,1].set_ylabel('Trial')\n",
    "ax[0,1].set_xlabel('Pos. (cm)')\n",
    "\n",
    "ax[0,2].imshow(angles[2].reshape(-1,int(L/bs)),cmap='hsv')\n",
    "ax[0,2].set_title(r'$\\theta_3$')\n",
    "for ts in trial_starts[1:-1]:\n",
    "    ax[0,2].axhline(ts,color='k',linestyle='dashed',linewidth=1)\n",
    "ax[0,2].set_ylabel('Trial')\n",
    "ax[0,2].set_xlabel('Pos. (cm)')\n",
    "\n",
    "plt.tight_layout(w_pad=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_pearson_r(x, y, window):\n",
    "    r_values = np.full(len(x), np.nan)\n",
    "    for i in range(window - 1, len(x)):\n",
    "        x_window = x[i - window + 1:i + 1]\n",
    "        y_window = y[i - window + 1:i + 1]\n",
    "        if len(x_window) == window and len(y_window) == window:\n",
    "            r = np.corrcoef(x_window, y_window)[0, 1]\n",
    "            r_values[i] = r\n",
    "    return r_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute angular differences with wrap-around\n",
    "dtheta1 = np.diff(angles_time[0])\n",
    "dtheta2 = np.diff(angles_time[1])\n",
    "\n",
    "# Wrap-around correction for circular dimensions\n",
    "dtheta1 = np.mod(dtheta1 + np.pi, 2 * np.pi) - np.pi\n",
    "dtheta2 = np.mod(dtheta2 + np.pi, 2 * np.pi) - np.pi\n",
    "\n",
    "# Compute Euclidean distance in angular space\n",
    "torus_distances = np.sqrt(dtheta1**2 + dtheta2**2)\n",
    "\n",
    "# Compute instantaneous speed\n",
    "torus_speed = torus_distances / (time_bs/1000)\n",
    "\n",
    "# smooth and zscore\n",
    "torus_speed = gaussian_filter1d(torus_speed, 1)\n",
    "speed_in_time = gaussian_filter1d(speed_in_time, 1)\n",
    "\n",
    "ztorus_speed = zscore(torus_speed)\n",
    "zspeed = zscore(speed_in_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_colors_in_time = []\n",
    "trial_group_in_time = []\n",
    "trial_type_in_time = []\n",
    "for tn in trial_number_in_time:\n",
    "    trial = beh['trials'][beh['trials']['number']==tn]\n",
    "    group=(trial['context'][0], \n",
    "           trial['type'][0],\n",
    "           trial['performance'][0])\n",
    "    c = get_color_for_group(group)\n",
    "    trial_group_in_time.append(group)\n",
    "    trial_colors_in_time.append(c)\n",
    "    trial_type_in_time.append(trial['type'][0])\n",
    "trial_colors_in_time = np.array(trial_colors_in_time)\n",
    "trial_group_in_time = np.array(trial_group_in_time)\n",
    "trial_type_in_time = np.array(trial_type_in_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding in time\n",
    "grid_ids_from_modules = [item for sublist in grid_module_cluster_ids for item in sublist]\n",
    "grid_tcs_time = {cluster_id: tcs_time[cluster_id] for cluster_id in grid_ids_from_modules if cluster_id in tcs_time}\n",
    "\n",
    "speed_in_time = np.array(speed_in_time)\n",
    "pos_in_time = np.array(pos_in_time) \n",
    "trial_number_in_time = np.array(trial_number_in_time)\n",
    "dt_in_time = np.array(dt_in_time)\n",
    "tns_to_decode_with = np.array(beh['trials']['number'])\n",
    "tns_to_decode_with = tns_to_decode_with[tns_to_decode_with<=np.nanmax(trial_number_in_time)]\n",
    "trial_types = np.array(beh['trials']['type'])\n",
    "\n",
    "tns_to_decode = np.array(beh['trials']['number']) # decode all trials to visualise\n",
    "tns_to_train = np.array(beh['trials']['number'][np.isin(beh['trials']['type'], np.array(['b','nb']))]) \n",
    "tns_to_decode = tns_to_decode[tns_to_decode<=np.nanmax(trial_number_in_time)] # handles last ephys trials\n",
    "tns_to_train = tns_to_train[tns_to_train<=np.nanmax(trial_number_in_time)] # handles last ephys trials\n",
    "\n",
    "predictions_in_time, errors_in_time = cross_validate_decoder_time(grid_tcs_time, \n",
    "                                                true_position=pos_in_time, \n",
    "                                                trial_numbers=trial_number_in_time, \n",
    "                                                tns_to_decode=tns_to_decode, \n",
    "                                                tns_to_train=tns_to_train, \n",
    "                                                tl=tl, bs=bs, train=0.9, n=10, verbose=False)\n",
    "\n",
    "avg_predictions_in_time = [np.mean(np.stack(preds_n), axis=0) for preds_n in predictions_in_time]\n",
    "avg_predictions_in_time = np.concatenate(avg_predictions_in_time).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_30seconds_speed = rolling_pearson_r(zspeed, ztorus_speed, window=300)\n",
    "reg_20seconds_speed = rolling_pearson_r(zspeed, ztorus_speed, window=200)\n",
    "reg_10seconds_speed = rolling_pearson_r(zspeed, ztorus_speed, window=100)\n",
    "reg_5seconds_speed = rolling_pearson_r(zspeed, ztorus_speed, window=50)\n",
    "reg_1seconds_speed = rolling_pearson_r(zspeed, ztorus_speed, window=10)\n",
    "\n",
    "# Plot the speed over time\n",
    "fig, ax = plt.subplots(ncols=1, nrows=2, figsize=(10, 2), sharex=True)\n",
    "start=3200\n",
    "stop=6200\n",
    "print(f'showing window from {trial_number_in_time[start]-trial_number_in_time[0]} to {trial_number_in_time[stop]-trial_number_in_time[0]}')\n",
    "ax[0].axhline(0, color='grey', linestyle='--', linewidth=0.5)\n",
    "ax[0].set_ylim([-0.5, 1])\n",
    "ax[0].plot(np.arange(0, len(ztorus_speed)*(time_bs/1000), (time_bs/1000))[start:stop], reg_20seconds_speed[start:stop], label='20 seconds', color='tab:grey')\n",
    "ax[1].plot(np.arange(0, len(ztorus_speed)*(time_bs/1000), (time_bs/1000))[start:stop], ztorus_speed[start:stop], color='tab:purple', label='Torus Speed')\n",
    "ax[1].plot(np.arange(0, len(zspeed)*(time_bs/1000), (time_bs/1000))[start:stop], zspeed[start:stop], color='black', label='Track Speed')\n",
    "ax[1].set_xlabel('Time (seconds)')\n",
    "ax[1].set_ylabel('Z-scored\\nSpeed')\n",
    "ax[0].set_ylabel('R')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/FIGURE2/GC_torus_snippet1_{mouse}D{day}.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the speed over time\n",
    "fig, ax = plt.subplots(ncols=1, nrows=2, figsize=(10, 2), sharex=True)\n",
    "start=10000\n",
    "stop=13000\n",
    "print(f'showing window from {trial_number_in_time[start]-trial_number_in_time[0]} to {trial_number_in_time[stop]-trial_number_in_time[0]}')\n",
    "ax[0].axhline(0, color='grey', linestyle='--', linewidth=0.5)\n",
    "ax[0].set_ylim([-0.5, 1])\n",
    "ax[0].plot(np.arange(0, len(ztorus_speed)*(time_bs/1000), (time_bs/1000))[start:stop], reg_20seconds_speed[start:stop], label='20 seconds', color='tab:grey')\n",
    "ax[1].plot(np.arange(0, len(ztorus_speed)*(time_bs/1000), (time_bs/1000))[start:stop], ztorus_speed[start:stop], color='tab:purple', label='Torus Speed')\n",
    "ax[1].plot(np.arange(0, len(zspeed)*(time_bs/1000), (time_bs/1000))[start:stop], zspeed[start:stop], color='black', label='Track Speed')\n",
    "ax[1].set_xlabel('Time (seconds)')\n",
    "ax[1].set_ylabel('Z-scored\\nSpeed')\n",
    "ax[0].set_ylabel('R')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/FIGURE2/GC_torus_snippet2_{mouse}D{day}.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the speed over time\n",
    "fig, ax = plt.subplots(ncols=1, nrows=2, figsize=(10, 2), sharex=True)\n",
    "start=1400\n",
    "stop=17000\n",
    "print(f'showing window from {trial_number_in_time[start]-trial_number_in_time[0]} to {trial_number_in_time[stop]-trial_number_in_time[0]}')\n",
    "ax[0].axhline(0, color='grey', linestyle='--', linewidth=0.5)\n",
    "ax[0].set_ylim([-0.5, 1])\n",
    "ax[0].plot(np.arange(0, len(ztorus_speed)*(time_bs/1000), (time_bs/1000))[start:stop], reg_20seconds_speed[start:stop], label='20 seconds', color='tab:grey')\n",
    "ax[1].plot(np.arange(0, len(ztorus_speed)*(time_bs/1000), (time_bs/1000))[start:stop], ztorus_speed[start:stop], color='tab:purple', label='Torus Speed')\n",
    "ax[1].plot(np.arange(0, len(zspeed)*(time_bs/1000), (time_bs/1000))[start:stop], zspeed[start:stop], color='black', label='Track Speed')\n",
    "ax[1].set_xlabel('Time (seconds)')\n",
    "ax[1].set_ylabel('Z-scored\\nSpeed')\n",
    "ax[0].set_ylabel('R')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/FIGURE2/GC_torus_snippet3_{mouse}D{day}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_30seconds_pos = rolling_pearson_r(pos_in_time, avg_predictions_in_time, window=300)\n",
    "reg_20seconds_pos = rolling_pearson_r(pos_in_time, avg_predictions_in_time, window=200)\n",
    "reg_10seconds_pos = rolling_pearson_r(pos_in_time, avg_predictions_in_time, window=100)\n",
    "reg_5seconds_pos = rolling_pearson_r(pos_in_time, avg_predictions_in_time, window=50)\n",
    "reg_1seconds_pos = rolling_pearson_r(pos_in_time, avg_predictions_in_time, window=10)\n",
    "\n",
    "\n",
    "# Plot the speed over time\n",
    "fig, ax = plt.subplots(ncols=1, nrows=2, figsize=(10, 2), sharex=True)\n",
    "start=3200\n",
    "stop=6200\n",
    "print(f'showing window from {trial_number_in_time[start]-trial_number_in_time[0]} to {trial_number_in_time[stop]-trial_number_in_time[0]}')\n",
    "ax[0].axhline(0, color='grey', linestyle='--', linewidth=0.5)\n",
    "ax[0].set_ylim([-0.5, 1])\n",
    "ax[0].plot(np.arange(0, len(ztorus_speed)*(time_bs/1000), (time_bs/1000))[start:stop], reg_20seconds_pos[start:stop], label='20 seconds', color='tab:grey')\n",
    "ax[1].plot(np.arange(0, len(avg_predictions_in_time)*(time_bs/1000), (time_bs/1000))[start:stop], avg_predictions_in_time[start:stop], color='red', label='decoded from grid')\n",
    "ax[1].plot(np.arange(0, len(avg_predictions_in_time)*(time_bs/1000), (time_bs/1000))[start:stop], pos_in_time[start:stop], color='black',label='true pos')\n",
    "ax[1].set_xlabel('Time (seconds)')\n",
    "ax[1].set_ylabel('Pos (cm)')\n",
    "ax[0].set_ylabel('R')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/FIGURE2/GC_decode_snippet1_{mouse}D{day}.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the speed over time\n",
    "fig, ax = plt.subplots(ncols=1, nrows=2, figsize=(10, 2), sharex=True)\n",
    "start=10000\n",
    "stop=13000\n",
    "print(f'showing window from {trial_number_in_time[start]-trial_number_in_time[0]} to {trial_number_in_time[stop]-trial_number_in_time[0]}')\n",
    "ax[0].axhline(0, color='grey', linestyle='--', linewidth=0.5)\n",
    "ax[0].set_ylim([-0.5, 1])\n",
    "ax[0].plot(np.arange(0, len(ztorus_speed)*(time_bs/1000), (time_bs/1000))[start:stop], reg_20seconds_pos[start:stop], label='20 seconds', color='tab:grey')\n",
    "ax[1].plot(np.arange(0, len(avg_predictions_in_time)*(time_bs/1000), (time_bs/1000))[start:stop], avg_predictions_in_time[start:stop], color='red', label='decoded from grid')\n",
    "ax[1].plot(np.arange(0, len(avg_predictions_in_time)*(time_bs/1000), (time_bs/1000))[start:stop], pos_in_time[start:stop], color='black',label='true pos')\n",
    "ax[1].set_xlabel('Time (seconds)')\n",
    "ax[1].set_ylabel('Pos (cm)')\n",
    "ax[0].set_ylabel('R')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/FIGURE2/GC_decode_snippet2_{mouse}D{day}.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the speed over time\n",
    "fig, ax = plt.subplots(ncols=1, nrows=2, figsize=(10, 2), sharex=True)\n",
    "start=14000\n",
    "stop=17000\n",
    "print(f'showing window from {trial_number_in_time[start]-trial_number_in_time[0]} to {trial_number_in_time[stop]-trial_number_in_time[0]}')\n",
    "ax[0].axhline(0, color='grey', linestyle='--', linewidth=0.5)\n",
    "ax[0].set_ylim([-0.5, 1])\n",
    "ax[0].plot(np.arange(0, len(ztorus_speed)*(time_bs/1000), (time_bs/1000))[start:stop], reg_20seconds_pos[start:stop], label='20 seconds', color='tab:grey')\n",
    "ax[1].plot(np.arange(0, len(avg_predictions_in_time)*(time_bs/1000), (time_bs/1000))[start:stop], avg_predictions_in_time[start:stop], color='red', label='decoded from grid')\n",
    "ax[1].plot(np.arange(0, len(avg_predictions_in_time)*(time_bs/1000), (time_bs/1000))[start:stop], pos_in_time[start:stop], color='black',label='true pos')\n",
    "ax[1].set_xlabel('Time (seconds)')\n",
    "ax[1].set_ylabel('Pos (cm)')\n",
    "ax[0].set_ylabel('R')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/FIGURE2/GC_decode_snippet3_{mouse}D{day}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(4, 2), sharex=True, sharey=True)\n",
    "ax[0].scatter(reg_20seconds_pos[trial_type_in_time=='b'], \n",
    "              reg_20seconds_speed[trial_type_in_time=='b'], s=0.3, \n",
    "              color=trial_colors_in_time[trial_type_in_time=='b'], alpha=0.1)\n",
    "ax[1].scatter(reg_20seconds_pos[trial_type_in_time=='nb'], \n",
    "              reg_20seconds_speed[trial_type_in_time=='nb'], s=0.3, \n",
    "              color=trial_colors_in_time[trial_type_in_time=='nb'], alpha=0.1)\n",
    "ax[0].set_ylabel('R speed')\n",
    "ax[0].set_xlabel('R pos')\n",
    "ax[1].set_xlabel('R pos')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(4, 2), sharex=True, sharey=True)\n",
    "\n",
    "# For 'b' trial type\n",
    "nan_mask_b = np.isfinite(reg_20seconds_pos[trial_type_in_time == 'b']) & np.isfinite(reg_20seconds_speed[trial_type_in_time == 'b'])\n",
    "x_b = reg_20seconds_pos[trial_type_in_time == 'b'][nan_mask_b]\n",
    "y_b = reg_20seconds_speed[trial_type_in_time == 'b'][nan_mask_b]\n",
    "c_b = trial_colors_in_time[trial_type_in_time == 'b'][nan_mask_b]\n",
    "ax[0].scatter(x_b, y_b, s=0.3, color=c_b, alpha=0.1, rasterized=True)\n",
    "\n",
    "df_b = pd.DataFrame({'pos': x_b, \n",
    "                     'speed': y_b, \n",
    "                     'tn': trial_type_in_time[trial_type_in_time == 'b'][nan_mask_b],\n",
    "                     'time': np.arange(len(x_b))})\n",
    "\n",
    "# Fit the linear mixed-effects model\n",
    "model = smf.mixedlm(\"speed ~ pos\", data=df_b, groups=df_b[\"tn\"], re_formula=\"~time\")\n",
    "result = model.fit()\n",
    "# Extract p-values for fixed effects\n",
    "print(\"P-values for fixed effects:\")\n",
    "print(result.pvalues)\n",
    "\n",
    "\n",
    "# Linear regression for 'b'\n",
    "slope_b, intercept_b, r_value_b, p_value_b, _ = linregress(x_b, y_b)\n",
    "ax[0].plot(x_b, slope_b * x_b + intercept_b, color='black', linewidth=1)\n",
    "#ax[0].text(0.05, 0.95, f\"$R^2$: {r_value_b**2:.2f}\\n$p$: {p_value_b:.2e}\", \n",
    "#           transform=ax[0].transAxes, fontsize=8, verticalalignment='top')\n",
    "\n",
    "# For 'nb' trial type\n",
    "nan_mask_nb = np.isfinite(reg_20seconds_pos[trial_type_in_time == 'nb']) & np.isfinite(reg_20seconds_speed[trial_type_in_time == 'nb'])\n",
    "x_nb = reg_20seconds_pos[trial_type_in_time == 'nb'][nan_mask_nb]\n",
    "y_nb = reg_20seconds_speed[trial_type_in_time == 'nb'][nan_mask_nb]\n",
    "c_nb = trial_colors_in_time[trial_type_in_time == 'nb'][nan_mask_nb]\n",
    "ax[1].scatter(x_nb, y_nb, s=0.3, color=c_nb, alpha=0.1, rasterized=True)\n",
    "\n",
    "# Linear regression for 'nb'\n",
    "slope_nb, intercept_nb, r_value_nb, p_value_nb, _ = linregress(x_nb, y_nb)\n",
    "ax[1].plot(x_nb, slope_nb * x_nb + intercept_nb, color='black', linewidth=1)\n",
    "#ax[1].text(0.05, 0.95, f\"$R^2$: {r_value_nb**2:.2f}\\n$p$: {p_value_nb:.2e}\", \n",
    "#           transform=ax[1].transAxes, fontsize=8, verticalalignment='top')\n",
    "\n",
    "ax[0].set_ylabel('R speed')\n",
    "ax[0].set_xlabel('R pos')\n",
    "ax[1].set_xlabel('R pos')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/FIGURE2/GC_regression_{mouse}D{day}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cats = beh['trials'][:int(last_ephys_bin/(tl/bs))].groupby(by=['context','type','performance'])\n",
    "sorted_cats = sort_dict_by_priority(sorted_cats, trial_cat_priority)\n",
    "\n",
    "sorted_trial_indices = []\n",
    "sorted_trial_colors = []\n",
    "sorted_block_sizes = []\n",
    "for group, cat_indices in zip(sorted_cats.keys(), sorted_cats.values()):\n",
    "    c = get_color_for_group(group)\n",
    "    sorted_trial_colors.extend(np.repeat(c, len(cat_indices)).tolist())\n",
    "    sorted_trial_indices.extend(cat_indices.tolist())\n",
    "    sorted_block_sizes.append(len(cat_indices))\n",
    "sorted_trial_colors = np.array(sorted_trial_colors)\n",
    "sorted_trial_indices = np.array(sorted_trial_indices)\n",
    "\n",
    "trial_colors = []\n",
    "trial_groups = []\n",
    "for trial in beh['trials'][:int(last_ephys_bin/(tl/bs))]:\n",
    "    group=(trial['context'][0], \n",
    "           trial['type'][0],\n",
    "           trial['performance'][0])\n",
    "    c = get_color_for_group(group)\n",
    "    trial_colors.append(c)\n",
    "    trial_groups.append(group)\n",
    "trial_colors = np.array(trial_colors)\n",
    "trial_groups = np.array(trial_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding \n",
    "grid_tcs = {cluster_id: tcs[cluster_id] for cluster_id in grid_cells.cluster_id if cluster_id in tcs}\n",
    "\n",
    "x_true_dt = dt_bins[:last_ephys_bin]\n",
    "true_position = x_true_dt%tl\n",
    "trial_numbers = (x_true_dt//tl)+beh['trials']['number'][0]\n",
    "tns_to_decode_with = np.array(beh['trials']['number'])\n",
    "tns_to_decode_with = tns_to_decode_with[tns_to_decode_with<=np.nanmax(trial_numbers)]\n",
    "trial_types = np.array(beh['trials']['type'])\n",
    "trial_types[np.argsort(trial_types)]\n",
    "\n",
    "tns_to_decode = np.array(beh['trials']['number']) # decode all trials to visualise\n",
    "tns_to_train = np.array(beh['trials']['number'][np.isin(beh['trials']['type'], np.array(['b','nb']))]) \n",
    "tns_to_decode = tns_to_decode[tns_to_decode<=np.nanmax(trial_numbers)] # handles last ephys trials\n",
    "tns_to_train = tns_to_train[tns_to_train<=np.nanmax(trial_numbers)] # handles last ephys trials\n",
    "\n",
    "predictions, errors = cross_validate_decoder(grid_tcs, true_position, trial_numbers, tns_to_decode, tns_to_train, tl, bs, train=0.9, n=10, verbose=False)\n",
    "avg_predictions = circular_nanmean(predictions, tl, axis=2)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(0.8, 2), width_ratios=[1,0.05], sharey=True)\n",
    "x = np.arange(1, len(avg_predictions)+1)\n",
    "y = np.arange(0, len(avg_predictions[0])*bs, bs)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "heatmap = ax[0].pcolormesh(Y, X, avg_predictions.T, shading='auto', cmap='hsv')\n",
    "heatmap.set_rasterized(True)\n",
    "ax[0].set_xlabel('Pos. (cm)')\n",
    "ax[1].axis('off')\n",
    "ax[1].scatter(np.ones(len(trial_colors)), \n",
    "                np.arange(0,len(trial_colors)), \n",
    "                c = trial_colors,\n",
    "                marker='s')\n",
    "ax[0].set_xlim(0,tl)\n",
    "ax[0].set_ylim(0,len(avg_predictions))\n",
    "ax[0].invert_yaxis()\n",
    "fig.savefig(f'/Users/harryclark/Documents/figs/decoding/GC_M{mouse}D{day}.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_predictions = predictions[sorted_trial_indices]\n",
    "sorted_errors = errors[sorted_trial_indices]\n",
    "\n",
    "avg_sorted_predictions = circular_nanmean(sorted_predictions, tl, axis=2)\n",
    "avg_sorted_errors = np.nanmean(sorted_errors, axis=2)\n",
    "\n",
    "b_error = np.arange(1,tl,bs) - circular_nanmean(avg_sorted_predictions[:len(trial_types[trial_types=='b'])], tl=tl, axis=0)\n",
    "nb_error = np.arange(1,tl,bs) - circular_nanmean(avg_sorted_predictions[len(trial_types[trial_types=='b']):], tl=tl, axis=0)\n",
    "\n",
    "plt.hist(b_error, color='tab:blue', bins=100,alpha=0.4)\n",
    "plt.hist(nb_error, color='tab:orange', bins=100,alpha=0.4)\n",
    "plt.title('errors before circular correction')\n",
    "plt.show()\n",
    "b_error[b_error>(tl*0.75)] = tl-b_error[b_error>(tl*0.75)]\n",
    "b_error[b_error<(-tl*0.75)] = tl+b_error[b_error<(-tl*0.75)]\n",
    "nb_error[nb_error>(tl*0.75)] = tl-nb_error[nb_error>(tl*0.75)]\n",
    "nb_error[nb_error<(-tl*0.75)] = tl+nb_error[nb_error<(-tl*0.75)]\n",
    "\n",
    "plt.hist(b_error, color='tab:blue', bins=100,alpha=0.4)\n",
    "plt.hist(nb_error, color='tab:orange', bins=100,alpha=0.4)\n",
    "plt.title('errors after circular correction')\n",
    "plt.show()\n",
    "\n",
    "norm = TwoSlopeNorm(vmin=-35,vcenter=0, vmax=35)\n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(2.5, 2), width_ratios=[1,1], height_ratios=[0.3,1], sharex=True)\n",
    "x = np.arange(1, len(avg_sorted_predictions)+1)\n",
    "y = np.arange(0, len(avg_sorted_predictions[0])*bs, bs)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "heatmap1 = ax[1,0].pcolormesh(Y, X, avg_sorted_predictions.T, shading='auto', cmap='hsv')\n",
    "heatmap1.set_rasterized(True)\n",
    "ax[1,0].set_xlabel('Pos. (cm)')\n",
    "ax[1,0].set_xlim(0,tl)\n",
    "ax[1,0].set_ylim(0,len(avg_sorted_predictions))\n",
    "ax[1,0].invert_yaxis()\n",
    "heatmap = ax[1,1].pcolormesh(Y, X, avg_sorted_errors.T, shading='auto', norm=norm, cmap='bwr')\n",
    "heatmap.set_rasterized(True)\n",
    "ax[1,1].set_xlabel('Pos. (cm)')\n",
    "ax[1,1].set_xlim(0,tl)\n",
    "ax[1,1].set_ylim(0,len(avg_sorted_errors))\n",
    "ax[1,1].invert_yaxis()\n",
    "ax[0,0].plot(y,y, color='black', linestyle='dashed')\n",
    "ax[0,0].plot(y, circular_nanmean(avg_sorted_predictions[:len(trial_types[trial_types=='b'])], tl=tl, axis=0), color='tab:blue')\n",
    "ax[0,0].plot(y, circular_nanmean(avg_sorted_predictions[len(trial_types[trial_types=='b']):], tl=tl, axis=0), color='tab:orange')\n",
    "ax[0,1].plot(np.arange(0,200,2), b_error, color='tab:blue')\n",
    "ax[0,1].plot(np.arange(0,200,2), nb_error, color='tab:orange')\n",
    "ax[1,0].set_xlabel(f'Pos (cm)')\n",
    "ax[1,1].set_xlabel(f'Pos (cm)')\n",
    "ax[1,1].set_yticklabels([])\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=None)\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/decoding/GC_M{mouse}D{day}_sorted.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# stops versus decoded position plot\n",
    "trial_numbers = np.array(beh['trial_number'])\n",
    "position = np.array(beh['P'])\n",
    "trial_types = np.array(beh['trial_type'])\n",
    "speed = np.array(beh['S'])\n",
    "stop_mask = speed<3\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(2, 2))\n",
    "\n",
    "sorted_cats = beh['trials'].groupby(by=['context','type','performance'])\n",
    "sorted_trial_indices = []\n",
    "sorted_trial_colors = []\n",
    "for group, cat_indices in zip(sorted_cats.keys(), sorted_cats.values()):\n",
    "    c = get_color_for_group(group)\n",
    "    sorted_trial_colors.extend(np.repeat(c, len(cat_indices)).tolist())\n",
    "    sorted_trial_indices.extend(cat_indices.tolist())\n",
    "sorted_trial_colors = np.array(sorted_trial_colors)\n",
    "sorted_trial_indices = np.array(sorted_trial_indices)\n",
    "\n",
    "for i, sti in enumerate(sorted_trial_indices):\n",
    "    tn_mask = trial_numbers==beh['trials'][sti]['number'].iloc[0]\n",
    "    stops = position[(stop_mask & tn_mask)]\n",
    "    decoded_pos = avg_predictions[sti]\n",
    "    argmax_pos = np.argmax(decoded_pos>90)\n",
    "    projected_stop = decoded_pos[argmax_pos]\n",
    "    print(projected_stop)\n",
    "    if len(stops)>0:\n",
    "        error = projected_stop - stops[0]\n",
    "    else:\n",
    "        error = np.nan\n",
    "    ax.plot([0, error], [i, i], color=sorted_trial_colors[i], alpha=0.5, linewidth=0.5)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding \n",
    "ng_tcs = {cluster_id: tcs[cluster_id] for cluster_id in non_grid_cells.cluster_id if cluster_id in tcs}\n",
    "\n",
    "x_true_dt = dt_bins[:last_ephys_bin]\n",
    "true_position = x_true_dt%tl\n",
    "trial_numbers = (x_true_dt//tl)+beh['trials']['number'][0]\n",
    "tns_to_decode_with = np.array(beh['trials']['number'])\n",
    "tns_to_decode_with = tns_to_decode_with[tns_to_decode_with<=np.nanmax(trial_numbers)]\n",
    "trial_types = np.array(beh['trials']['type'])\n",
    "trial_types[np.argsort(trial_types)]\n",
    "\n",
    "tns_to_decode = np.array(beh['trials']['number']) # decode all trials to visualise\n",
    "tns_to_train = np.array(beh['trials']['number'][np.isin(beh['trials']['type'], np.array(['b','nb']))]) \n",
    "tns_to_decode = tns_to_decode[tns_to_decode<=np.nanmax(trial_numbers)] # handles last ephys trials\n",
    "tns_to_train = tns_to_train[tns_to_train<=np.nanmax(trial_numbers)] # handles last ephys trials\n",
    "\n",
    "predictions, errors = cross_validate_decoder(ng_tcs, true_position, trial_numbers, tns_to_decode, tns_to_train, tl, bs, train=0.9, n=10, verbose=False)\n",
    "avg_predictions = circular_nanmean(predictions, tl, axis=2)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(0.8, 2), width_ratios=[1,0.05], sharey=True)\n",
    "x = np.arange(1, len(avg_predictions)+1)\n",
    "y = np.arange(0, len(avg_predictions[0])*bs, bs)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "heatmap = ax[0].pcolormesh(Y, X, avg_predictions.T, shading='auto', cmap='hsv')\n",
    "heatmap.set_rasterized(True)\n",
    "ax[0].set_xlabel('Pos. (cm)')\n",
    "ax[1].axis('off')\n",
    "ax[1].scatter(np.ones(len(trial_colors)), \n",
    "                np.arange(0,len(trial_colors)), \n",
    "                c = trial_colors,\n",
    "                marker='s')\n",
    "ax[0].set_xlim(0,tl)\n",
    "ax[0].set_ylim(0,len(avg_predictions))\n",
    "ax[0].invert_yaxis()\n",
    "fig.savefig(f'/Users/harryclark/Documents/figs/decoding/NG_M{mouse}D{day}.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "sorted_predictions = predictions[sorted_trial_indices]\n",
    "sorted_errors = errors[sorted_trial_indices]\n",
    "\n",
    "avg_sorted_predictions = circular_nanmean(sorted_predictions, tl, axis=2)\n",
    "avg_sorted_errors = np.nanmean(sorted_errors, axis=2)\n",
    "\n",
    "b_error = np.arange(1,tl,bs) - circular_nanmean(avg_sorted_predictions[:len(trial_types[trial_types=='b'])], tl=tl, axis=0)\n",
    "nb_error = np.arange(1,tl,bs) - circular_nanmean(avg_sorted_predictions[len(trial_types[trial_types=='b']):], tl=tl, axis=0)\n",
    "\n",
    "plt.hist(b_error, color='tab:blue', bins=100,alpha=0.4)\n",
    "plt.hist(nb_error, color='tab:orange', bins=100,alpha=0.4)\n",
    "plt.title('errors before circular correction')\n",
    "plt.show()\n",
    "b_error[b_error>(tl*0.75)] = tl-b_error[b_error>(tl*0.75)]\n",
    "b_error[b_error<(-tl*0.75)] = tl+b_error[b_error<(-tl*0.75)]\n",
    "nb_error[nb_error>(tl*0.75)] = tl-nb_error[nb_error>(tl*0.75)]\n",
    "nb_error[nb_error<(-tl*0.75)] = tl+nb_error[nb_error<(-tl*0.75)]\n",
    "\n",
    "plt.hist(b_error, color='tab:blue', bins=100,alpha=0.4)\n",
    "plt.hist(nb_error, color='tab:orange', bins=100,alpha=0.4)\n",
    "plt.title('errors after circular correction')\n",
    "plt.show()\n",
    "\n",
    "norm = TwoSlopeNorm(vmin=-35,vcenter=0, vmax=35)\n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(2.5, 2), width_ratios=[1,1], height_ratios=[0.3,1], sharex=True)\n",
    "x = np.arange(1, len(avg_sorted_predictions)+1)\n",
    "y = np.arange(0, len(avg_sorted_predictions[0])*bs, bs)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "heatmap1 = ax[1,0].pcolormesh(Y, X, avg_sorted_predictions.T, shading='auto', cmap='hsv')\n",
    "heatmap1.set_rasterized(True)\n",
    "ax[1,0].set_xlabel('Pos. (cm)')\n",
    "ax[1,0].set_xlim(0,tl)\n",
    "ax[1,0].set_ylim(0,len(avg_sorted_predictions))\n",
    "ax[1,0].invert_yaxis()\n",
    "heatmap = ax[1,1].pcolormesh(Y, X, avg_sorted_errors.T, shading='auto', norm=norm, cmap='bwr')\n",
    "heatmap.set_rasterized(True)\n",
    "ax[1,1].set_xlabel('Pos. (cm)')\n",
    "ax[1,1].set_xlim(0,tl)\n",
    "ax[1,1].set_ylim(0,len(avg_sorted_errors))\n",
    "ax[1,1].invert_yaxis()\n",
    "ax[0,0].plot(y,y, color='black', linestyle='dashed')\n",
    "ax[0,0].plot(y, circular_nanmean(avg_sorted_predictions[:len(trial_types[trial_types=='b'])], tl=tl, axis=0), color='tab:blue')\n",
    "ax[0,0].plot(y, circular_nanmean(avg_sorted_predictions[len(trial_types[trial_types=='b']):], tl=tl, axis=0), color='tab:orange')\n",
    "ax[0,1].plot(np.arange(0,200,2), b_error, color='tab:blue')\n",
    "ax[0,1].plot(np.arange(0,200,2), nb_error, color='tab:orange')\n",
    "ax[1,0].set_xlabel(f'Pos (cm)')\n",
    "ax[1,1].set_xlabel(f'Pos (cm)')\n",
    "ax[1,1].set_yticklabels([])\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=None)\n",
    "plt.savefig(f'/Users/harryclark/Documents/figs/decoding/NG_M{mouse}D{day}_sorted.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles1 = angles[0].reshape(-1,int(L/bs))\n",
    "angles2 = angles[1].reshape(-1,int(L/bs))\n",
    "angles3 = angles[2].reshape(-1,int(L/bs))\n",
    "\n",
    "for i, angles0 in  enumerate([angles1, angles2, angles3]):\n",
    "    fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(0.8, 2), width_ratios=[1,0.05], sharey=True)\n",
    "\n",
    "    x = np.arange(1, len(angles0)+1)\n",
    "    y = np.arange(0, len(angles0[0])*bs, bs)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    heatmap = ax[0].pcolormesh(Y, X, angles0.T, shading='auto', cmap='hsv')\n",
    "    heatmap.set_rasterized(True)\n",
    "    ax[0].set_xlabel('Pos. (cm)')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].scatter(np.ones(len(trial_colors)), \n",
    "                  np.arange(0,len(trial_colors)), \n",
    "                  c = trial_colors,\n",
    "                  marker='s')\n",
    "    ax[0].set_xlim(0,tl)\n",
    "    ax[0].set_ylim(0,len(angles0))\n",
    "    ax[0].invert_yaxis()\n",
    "    fig.savefig(f'/Users/harryclark/Documents/figs/toroidal/M{mouse}D{day}A{i}.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_correlation_per_matrix(matrix):\n",
    "    corrs = np.zeros((len(matrix), len(matrix)))\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            corrs[i,j] = stats.pearsonr(matrix[i], matrix[j])[0]\n",
    "    return np.nanmean(corrs)\n",
    "\n",
    "corr1 = average_correlation_per_matrix(angles1)\n",
    "corr2 = average_correlation_per_matrix(angles2)\n",
    "corr3 = average_correlation_per_matrix(angles3)\n",
    "\n",
    "print(\"corr angles1 :\\n\", corr1)\n",
    "print(\"corr angles2 :\\n\", corr2)\n",
    "print(\"corr angles3 :\\n\", corr3)\n",
    "\n",
    "best_angle1 = angles1\n",
    "best_angle2 = angles2\n",
    "\n",
    "if corr3 > corr1:\n",
    "    best_angle1 = angles3\n",
    "elif corr3 > corr2:\n",
    "    best_angle2 = angles3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles1_sorted = angles[0].reshape(-1,int(L/bs))[sorted_trial_indices]\n",
    "angles2_sorted = angles[1].reshape(-1,int(L/bs))[sorted_trial_indices]\n",
    "angles3_sorted = angles[2].reshape(-1,int(L/bs))[sorted_trial_indices]\n",
    "\n",
    "for i, angles0_sorted in enumerate([angles1_sorted, angles2_sorted, angles3_sorted]):\n",
    "    fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(0.8, 2), width_ratios=[1,0.05], sharey=True)\n",
    "\n",
    "    x = np.arange(1, len(angles0_sorted)+1)\n",
    "    y = np.arange(0, len(angles0_sorted[0])*bs, bs)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    ax[0].pcolormesh(Y, X, angles0_sorted.T, shading='auto', cmap='hsv')\n",
    "    ax[0].set_xlabel('Pos. (cm)')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].scatter(np.ones(len(sorted_trial_colors)), \n",
    "                  np.arange(0,len(sorted_trial_colors)), \n",
    "                  c = sorted_trial_colors,\n",
    "                  marker='s')\n",
    "    ax[0].set_xlim(0,tl)\n",
    "    ax[0].set_ylim(0,len(angles0_sorted))\n",
    "    ax[0].invert_yaxis()\n",
    "    fig.savefig(f'/Users/harryclark/Documents/figs/toroidal/M{mouse}D{day}A{i}_sorted.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(6,2), sharey=True, sharex=True)\n",
    "b_group = ('rz1', 'b', 'hit')\n",
    "nb_group = ('rz1', 'nb', 'hit')\n",
    "\n",
    "b_mask = np.all(trial_groups == b_group, axis=1)\n",
    "nb_mask = np.all(trial_groups == nb_group, axis=1)\n",
    "hit_mask = np.logical_or(b_mask, nb_mask)\n",
    "\n",
    "heatmap, xedges, yedges = np.histogram2d(best_angle1[hit_mask].flatten(), best_angle2[hit_mask].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "heatmap1, xedges, yedges = np.histogram2d(best_angle1[b_mask].flatten(), best_angle2[b_mask].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "heatmap2, xedges, yedges = np.histogram2d(best_angle1[nb_mask].flatten(), best_angle2[nb_mask].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "\n",
    "heatmap= gaussian_filter_nan(heatmap, sigma=(3,3))\n",
    "heatmap1= gaussian_filter_nan(heatmap1, sigma=(3,3))\n",
    "heatmap2= gaussian_filter_nan(heatmap2, sigma=(3,3))\n",
    "\n",
    "if np.any(np.isnan(heatmap)):\n",
    "    heatmap[:] = 1\n",
    "    heatmap1[:] = 1\n",
    "    heatmap2[:] = 1\n",
    "\n",
    "ax[0].pcolormesh(xedges, yedges, heatmap.T, cmap='jet')\n",
    "ax[1].pcolormesh(xedges, yedges, heatmap1.T, cmap='jet')\n",
    "ax[2].pcolormesh(xedges, yedges, heatmap2.T, cmap='jet')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.append(np.diff(np.array(beh['S'].index)), 0)\n",
    "position = np.array(beh['P'])\n",
    "travel = np.array(beh['travel'])\n",
    "speed = np.array(beh['S'])\n",
    "time_spent_in_each_bin = angles0.copy()\n",
    "\n",
    "dt_npy = np.array(beh['travel']-((tns[0]-1)*tl))\n",
    "n_bins = int(int(((np.ceil(np.nanmax(dt_npy))//tl)+1)*tl)/bs)\n",
    "max_bound = int(((np.ceil(np.nanmax(dt_npy))//tl)+1)*tl)\n",
    "min_bound = 0\n",
    "bins_visited, _ = np.histogram(position, bins=int(tl/bs), range=[0,tl])\n",
    "time_spent_in_bins, _ = np.histogram(position, weights=time, bins=int(tl/bs), range=[0,tl])\n",
    "time_spent_in_bins_per_trial = time_spent_in_bins/int(np.max(dt_npy)/tl)\n",
    "speed_in_bin_per_trial = bs/time_spent_in_bins_per_trial\n",
    "speed_in_bin_per_trial = gaussian_filter1d(speed_in_bin_per_trial, sigma=2)\n",
    "time_spent_in_bins_per_trial = bs/speed_in_bin_per_trial\n",
    "time_at_bin_centre = np.cumsum(time_spent_in_bins_per_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate 2d\n",
    "def interpolate_along_time_axis(time_at_bin_centre, heatmap):\n",
    "    import numpy as np\n",
    "    from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "    # Example data\n",
    "    # Replace these with your actual matrices and time values\n",
    "    time_values = time_at_bin_centre\n",
    "\n",
    "    # Define the new time grid (every 100 milliseconds)\n",
    "    new_time_grid = np.arange(time_values.min(), time_values.max(), 0.1)\n",
    "\n",
    "    # Define the spatial grid\n",
    "    x = np.arange(heatmap.shape[1])  # 100\n",
    "    y = np.arange(heatmap.shape[2])  # 100\n",
    "\n",
    "    # Create the interpolator\n",
    "    interpolator = RegularGridInterpolator((time_values, x, y), heatmap)\n",
    "\n",
    "    # Generate the new grid points for interpolation\n",
    "    T, X, Y = np.meshgrid(new_time_grid, x, y, indexing='ij')\n",
    "    points = np.stack([T.ravel(), X.ravel(), Y.ravel()], axis=-1)\n",
    "\n",
    "    # Perform the interpolation\n",
    "    interpolated_values = interpolator(points)\n",
    "\n",
    "    # Reshape to (num_new_times, x, y)\n",
    "    interpolated_matrices = interpolated_values.reshape(len(new_time_grid), len(x), len(y))\n",
    "\n",
    "    return interpolated_matrices\n",
    "\n",
    "def interpolate_bin_centres_in_time(time_at_bin_centre, bin_centres):\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    # Example input data\n",
    "    # Replace these with your actual time and position values\n",
    "    time_values = time_at_bin_centre # Time at bin centers (in seconds)\n",
    "    positions = bin_centres       # Position at each bin center\n",
    "\n",
    "    # Define the new time grid (every 100 milliseconds)\n",
    "    new_time_grid = np.arange(time_values.min(), time_values.max(), 0.1)\n",
    "\n",
    "    # Create the interpolator\n",
    "    interpolator = interp1d(time_values, positions, kind='linear')\n",
    "\n",
    "    # Interpolate positions at the new time points\n",
    "    interpolated_positions = interpolator(new_time_grid)\n",
    "    return interpolated_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_smooth_crop_heatmap(heatmap, sigma=(3,3)):\n",
    "    # handles circulurity\n",
    "    rows, cols = heatmap.shape\n",
    "    tiled_heatmap = np.tile(heatmap, (3, 3))\n",
    "    tiled_heatmap= gaussian_filter_nan(tiled_heatmap, sigma=sigma)\n",
    "    cropped_heatmap = tiled_heatmap[rows:2*rows, cols:2*cols]\n",
    "    return cropped_heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "norm = TwoSlopeNorm(vmin=-0.2,vcenter=0,vmax=0.2)\n",
    "\n",
    "# Generate sample heatmap data (replace this with your actual data)\n",
    "heatmap_data_all = []\n",
    "for i in range(0,100):\n",
    "    heatmap, xedges, yedges = np.histogram2d(best_angle1[hit_mask][:,i*1:i*1+1].flatten(), best_angle2[hit_mask][:,i*1:i*1+1].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "    heatmap= tile_smooth_crop_heatmap(heatmap, sigma=(3,3))\n",
    "    heatmap_data_all.append(heatmap)\n",
    "heatmap_data_all=np.array(heatmap_data_all)\n",
    "\n",
    "heatmap_data_b = []\n",
    "for i in range(0,100):\n",
    "    heatmap, xedges, yedges = np.histogram2d(best_angle1[b_mask][:,i*1:i*1+1].flatten(), best_angle2[b_mask][:,i*1:i*1+1].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "    heatmap= tile_smooth_crop_heatmap(heatmap, sigma=(3,3))\n",
    "    heatmap_data_b.append(heatmap)\n",
    "heatmap_data_b=np.array(heatmap_data_b)\n",
    "\n",
    "heatmap_data_nb = []\n",
    "for i in range(0,100):\n",
    "    heatmap, xedges, yedges = np.histogram2d(best_angle1[nb_mask][:,i*1:i*1+1].flatten(), best_angle2[nb_mask][:,i*1:i*1+1].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "    heatmap= tile_smooth_crop_heatmap(heatmap, sigma=(3,3))\n",
    "    heatmap_data_nb.append(heatmap)\n",
    "heatmap_data_nb=np.array(heatmap_data_nb)\n",
    "\n",
    "heatmap_data_all = interpolate_along_time_axis(time_at_bin_centre, heatmap_data_all)\n",
    "heatmap_data_b = interpolate_along_time_axis(time_at_bin_centre, heatmap_data_b)\n",
    "heatmap_data_nb = interpolate_along_time_axis(time_at_bin_centre, heatmap_data_nb)\n",
    "bin_centres = interpolate_bin_centres_in_time(time_at_bin_centre, np.arange(0,tl,bs))\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, axs = plt.subplots(ncols=4, nrows=2, figsize=(6,2.5), sharey=True, sharex=True, height_ratios=[0.1,1])\n",
    "ax0 = axs[1,0].imshow(heatmap_data_all[0], cmap='jet', vmin=0, vmax=0.4)\n",
    "ax1 = axs[1,1].imshow(heatmap_data_b[0], cmap='jet', vmin=0, vmax=0.4)\n",
    "ax2 = axs[1,2].imshow(heatmap_data_nb[0], cmap='jet', vmin=0, vmax=0.4)\n",
    "ax3 = axs[1,3].imshow(heatmap_data_b[0]-heatmap_data_nb[0], cmap='bwr', norm=norm)\n",
    "\n",
    "axs[1,0].set_title('all hits')\n",
    "axs[1,1].set_title('cued hits')\n",
    "axs[1,2].set_title('uncued hits')\n",
    "axs[1,3].set_title('delta')\n",
    "axs[1,3].set_ylim(0,50)\n",
    "\n",
    "scat = axs[0,0].scatter(0, -50, color='black')\n",
    "text = axs[0,1].text(0,0,f'{0}')\n",
    "scalar=6\n",
    "axs[0,0].axvspan(0,200/scalar,\n",
    "        alpha=0.2,\n",
    "        zorder=-10,\n",
    "        edgecolor='none',\n",
    "        facecolor='grey',\n",
    "    )\n",
    "#axs[0,0].axvspan(90/scalar,110/scalar,\n",
    "#        alpha=1,\n",
    "#        zorder=-10,\n",
    "#        edgecolor='none',\n",
    "#        facecolor='lightgreen',\n",
    "#    )\n",
    "\n",
    "axs[0,0].axvline(90/scalar, color='black', linestyle='dotted', linewidth=0.5)\n",
    "axs[0,0].axvline(110/scalar, color='black', linestyle='dotted', linewidth=0.5)\n",
    "\n",
    "\n",
    "axs[0,0].axvspan(0,30/scalar,\n",
    "        alpha=0.5,\n",
    "        zorder=-10,\n",
    "        edgecolor='none',\n",
    "        facecolor='darkgrey',\n",
    "    )\n",
    "axs[0,0].axvspan(170/scalar,200/scalar,\n",
    "        alpha=0.5,\n",
    "        zorder=-10,\n",
    "        edgecolor='none',\n",
    "        facecolor='darkgrey',\n",
    "    )\n",
    "\n",
    "x_data = bin_centres/scalar\n",
    "y_data = np.ones(len(x_data))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.axis('off')\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    text.set_text(f'Trial time: {np.round(frame*frame_interval/1000, decimals=1)} seconds')\n",
    "    scat.set_offsets(np.c_[x_data[frame], y_data[frame]])\n",
    "    ax0.set_array(heatmap_data_all[frame])\n",
    "    ax1.set_array(heatmap_data_b[frame])\n",
    "    ax2.set_array(heatmap_data_nb[frame])\n",
    "    ax3.set_array(heatmap_data_b[frame]-heatmap_data_nb[frame])\n",
    "\n",
    "    return ax,\n",
    "\n",
    "# Create animation\n",
    "frame_interval = 100\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(heatmap_data_b), blit=True, interval=frame_interval, repeat_delay=0)\n",
    "plt.tight_layout()\n",
    "ani.save(f'/Users/harryclark/Downloads/M{mouse}D{day}_activity_bump2.gif', writer='pillow')\n",
    "# Display the animation\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "# Example heatmap data (replace this with your own 2D NumPy array)\n",
    "heatmap = heatmap_data_nb[0]\n",
    "\n",
    "# Torus parameters\n",
    "R = 0.5  # Major radius\n",
    "r = 0.2  # Minor radius\n",
    "\n",
    "# Create a meshgrid for the torus\n",
    "u = np.linspace(0, 2 * np.pi, heatmap.shape[0])\n",
    "v = np.linspace(0, 2 * np.pi, heatmap.shape[1])\n",
    "u, v = np.meshgrid(u, v)\n",
    "\n",
    "# Parametric equations for the torus\n",
    "x = (R + r * np.cos(v)) * np.cos(u)\n",
    "y = (R + r * np.cos(v)) * np.sin(u)\n",
    "z = r * np.sin(v)\n",
    "\n",
    "for elev, azim, view_label in zip([90,0,45], [0,0,45], ['top', 'side', 'iso']):\n",
    "    # Create the figure and 3D axis\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "    # Map the heatmap values to the torus surface as colors\n",
    "    surf = ax.plot_surface(x, y, z, facecolors=plt.cm.jet(heatmap), \n",
    "                    rstride=1, cstride=1, antialiased=True,alpha=.4, edgecolor='none', vmin=0, vmax=0.2)\n",
    "    ax.set_zlim3d(-0.5, 0.5)\n",
    "\n",
    "    # Update function for animation\n",
    "    def update(frame):\n",
    "        global surf\n",
    "        surf.remove()\n",
    "        surf = ax.plot_surface(x, y, z, facecolors=plt.cm.jet(heatmap_data_nb[frame]*2), \n",
    "                    rstride=1, cstride=1, antialiased=True, alpha=.7, edgecolor='none', vmin=0, vmax=0.2)\n",
    "        return surf,\n",
    "\n",
    "    # Create animation\n",
    "    frame_interval = 100\n",
    "    ani = animation.FuncAnimation(fig, update, frames=len(heatmap_data_b), blit=True, interval=frame_interval, repeat_delay=0)\n",
    "    plt.tight_layout()\n",
    "    ani.save(f'/Users/harryclark/Downloads/M{mouse}D{day}_activity_bump_torus_{view_label}.gif', writer='pillow')\n",
    "    # Display the animation\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(ncols=7, nrows=7, figsize=(10,10), sharey=True, sharex=True)\n",
    "norm = TwoSlopeNorm(vmin=-0.2,vcenter=0,vmax=0.2)\n",
    "for i, group in enumerate([('rz1', 'b', 'hit'), ('rz1', 'b', 'try'), ('rz1', 'b', 'run'), ('rz1', 'nb', 'hit'), ('rz1', 'nb', 'try'), ('rz1', 'nb', 'run')]):\n",
    "    t_mask = np.all(trial_groups == group, axis=1)\n",
    "    \n",
    "    c = get_color_for_group(group)\n",
    "\n",
    "    heatmap, xedges, yedges = np.histogram2d(best_angle1[t_mask].flatten(), best_angle2[t_mask].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "    heatmap1, xedges, yedges = np.histogram2d(best_angle1[t_mask][:,0:20].flatten(), best_angle2[t_mask][:,0:20].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "    heatmap2, xedges, yedges = np.histogram2d(best_angle1[t_mask][:,20:40].flatten(), best_angle2[t_mask][:,20:40].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "    heatmap3, xedges, yedges = np.histogram2d(best_angle1[t_mask][:,40:60].flatten(), best_angle2[t_mask][:,40:60].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "    heatmap4, xedges, yedges = np.histogram2d(best_angle1[t_mask][:,60:80].flatten(), best_angle2[t_mask][:,60:80].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "    heatmap5, xedges, yedges = np.histogram2d(best_angle1[t_mask][:,80:100].flatten(), best_angle2[t_mask][:,80:100].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "\n",
    "    heatmap=  tile_smooth_crop_heatmap(heatmap, sigma=(3,3))\n",
    "    heatmap1= tile_smooth_crop_heatmap(heatmap1, sigma=(3,3))\n",
    "    heatmap2= tile_smooth_crop_heatmap(heatmap2, sigma=(3,3))\n",
    "    heatmap3= tile_smooth_crop_heatmap(heatmap3, sigma=(3,3))\n",
    "    heatmap4= tile_smooth_crop_heatmap(heatmap4, sigma=(3,3))\n",
    "    heatmap5= tile_smooth_crop_heatmap(heatmap5, sigma=(3,3))\n",
    "\n",
    "    if np.any(np.isnan(heatmap)):\n",
    "        heatmap[:] = 1\n",
    "        heatmap1[:] = 1\n",
    "        heatmap2[:] = 1\n",
    "        heatmap3[:] = 1\n",
    "        heatmap4[:] = 1\n",
    "        heatmap5[:] = 1\n",
    "\n",
    "    ax[0,i].pcolormesh(xedges, yedges, heatmap.T, cmap='jet',  vmin=0, vmax=0.4)\n",
    "    ax[1,i].pcolormesh(xedges, yedges, heatmap1.T, cmap='jet', vmin=0, vmax=0.4)\n",
    "    ax[2,i].pcolormesh(xedges, yedges, heatmap2.T, cmap='jet', vmin=0, vmax=0.4)\n",
    "    ax[3,i].pcolormesh(xedges, yedges, heatmap3.T, cmap='jet', vmin=0, vmax=0.4)\n",
    "    ax[4,i].pcolormesh(xedges, yedges, heatmap4.T, cmap='jet', vmin=0, vmax=0.4)\n",
    "    ax[5,i].pcolormesh(xedges, yedges, heatmap5.T, cmap='jet', vmin=0, vmax=0.4)\n",
    "\n",
    "h_b_mask = np.all(trial_groups == ('rz1', 'b', 'hit'), axis=1)\n",
    "h_nb_mask = np.all(trial_groups == ('rz1', 'nb', 'hit'), axis=1)\n",
    "segments = [0,20,40,60,80,100,120]\n",
    "for i, segment in enumerate(segments[:-1]):\n",
    "    heatmap_h_b, xedges, yedges = np.histogram2d(best_angle1[h_b_mask][:, segments[i]:segments[i+1]].flatten(), best_angle2[h_b_mask][:, segments[i]:segments[i+1]].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "    heatmap_h_nb, xedges, yedges = np.histogram2d(best_angle1[h_nb_mask][:, segments[i]:segments[i+1]].flatten(), best_angle2[h_nb_mask][:, segments[i]:segments[i+1]].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "    heatmap_h_b= tile_smooth_crop_heatmap(heatmap_h_b, sigma=(3,3))\n",
    "    heatmap_h_nb= tile_smooth_crop_heatmap(heatmap_h_nb, sigma=(3,3))\n",
    "    diff_h= heatmap_h_b-heatmap_h_nb\n",
    "    ax[i+1,6].pcolormesh(xedges, yedges, diff_h.T, cmap='bwr', norm=norm)\n",
    "heatmap_h_b, xedges, yedges = np.histogram2d(best_angle1[h_b_mask].flatten(), best_angle2[h_b_mask].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "heatmap_h_nb, xedges, yedges = np.histogram2d(best_angle1[h_nb_mask].flatten(), best_angle2[h_nb_mask].flatten(), bins=50, range=[[-np.pi, np.pi], [-np.pi, np.pi]], density=True)\n",
    "heatmap_h_b= tile_smooth_crop_heatmap(heatmap_h_b, sigma=(3,3))\n",
    "heatmap_h_nb= tile_smooth_crop_heatmap(heatmap_h_nb, sigma=(3,3))\n",
    "\n",
    "diff_h= heatmap_h_b-heatmap_h_nb\n",
    "ax[0,6].pcolormesh(xedges, yedges, diff_h.T, cmap='bwr', norm=norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in cluster_ids_by_group[0]:\n",
    "    tc = nap.compute_1d_tuning_curves(nap.TsGroup([clusters[cell]]), \n",
    "                                      dt, \n",
    "                                      nb_bins=n_bins, \n",
    "                                      minmax=[min_bound, max_bound],\n",
    "                                      ep=beh[\"moving\"])[0]\n",
    "    mask = np.isnan(tc)\n",
    "    tc = gaussian_filter(np.nan_to_num(tc).astype(np.float64), sigma=2.5)\n",
    "    tc = zscore(tc)\n",
    "    tc = tc[:last_ephys_bin] # only want bins with ephys data in it\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(0.8, 2), width_ratios=[1,0.05], sharey=True)\n",
    "    plot_firing_rate_map(ax[0], tc, bs=bs, tl=tl,p=95, sort_indices=None)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].scatter(np.ones(len(trial_colors)), \n",
    "                  np.arange(0,len(trial_colors)), \n",
    "                  c = trial_colors,\n",
    "                  marker='s')\n",
    "    ax[0].set_xlabel('Pos (cm)')\n",
    "\n",
    "    fig.savefig(f'/Users/harryclark/Documents/figs/rate_map_examples/M{mouse}D{day}GC{cell}.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in cluster_ids_by_group[-2]:\n",
    "    tc = nap.compute_1d_tuning_curves(nap.TsGroup([clusters[cell]]), \n",
    "                                      dt, \n",
    "                                      nb_bins=n_bins, \n",
    "                                      minmax=[min_bound, max_bound],\n",
    "                                      ep=beh[\"moving\"])[0]\n",
    "    mask = np.isnan(tc)\n",
    "    tc = gaussian_filter(np.nan_to_num(tc).astype(np.float64), sigma=2.5)\n",
    "    tc = zscore(tc)\n",
    "    tc = tc[:last_ephys_bin] # only want bins with ephys data in it\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(0.8, 2), width_ratios=[1,0.05], sharey=True)\n",
    "    plot_firing_rate_map(ax[0], tc, bs=bs, tl=tl,p=95, sort_indices=None)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].scatter(np.ones(len(trial_colors)), \n",
    "                  np.arange(0,len(trial_colors)), \n",
    "                  c = trial_colors,\n",
    "                  marker='s')\n",
    "    ax[0].set_xlabel('Pos (cm)')\n",
    "\n",
    "    fig.savefig(f'/Users/harryclark/Documents/figs/rate_map_examples/M{mouse}D{day}NGS{cell}.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
